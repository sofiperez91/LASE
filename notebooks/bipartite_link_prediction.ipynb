{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Link Prediction on Cora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.x\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.tx\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.allx\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.y\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ty\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ally\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.graph\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.test.index\n",
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.6930, Val: 0.6833, Test: 0.7031\n",
      "Epoch: 002, Loss: 0.6833, Val: 0.6812, Test: 0.6972\n",
      "Epoch: 003, Loss: 0.7039, Val: 0.6885, Test: 0.7066\n",
      "Epoch: 004, Loss: 0.6784, Val: 0.6980, Test: 0.7239\n",
      "Epoch: 005, Loss: 0.6852, Val: 0.7068, Test: 0.7394\n",
      "Epoch: 006, Loss: 0.6878, Val: 0.7131, Test: 0.7451\n",
      "Epoch: 007, Loss: 0.6883, Val: 0.7073, Test: 0.7348\n",
      "Epoch: 008, Loss: 0.6870, Val: 0.6965, Test: 0.7197\n",
      "Epoch: 009, Loss: 0.6830, Val: 0.6891, Test: 0.7076\n",
      "Epoch: 010, Loss: 0.6761, Val: 0.6857, Test: 0.6987\n",
      "Epoch: 011, Loss: 0.6698, Val: 0.6835, Test: 0.6920\n",
      "Epoch: 012, Loss: 0.6734, Val: 0.6832, Test: 0.6921\n",
      "Epoch: 013, Loss: 0.6685, Val: 0.6930, Test: 0.7060\n",
      "Epoch: 014, Loss: 0.6586, Val: 0.7174, Test: 0.7335\n",
      "Epoch: 015, Loss: 0.6553, Val: 0.7420, Test: 0.7504\n",
      "Epoch: 016, Loss: 0.6487, Val: 0.7464, Test: 0.7467\n",
      "Epoch: 017, Loss: 0.6378, Val: 0.7380, Test: 0.7356\n",
      "Epoch: 018, Loss: 0.6248, Val: 0.7408, Test: 0.7335\n",
      "Epoch: 019, Loss: 0.6165, Val: 0.7703, Test: 0.7496\n",
      "Epoch: 020, Loss: 0.5982, Val: 0.7870, Test: 0.7649\n",
      "Epoch: 021, Loss: 0.5883, Val: 0.7852, Test: 0.7658\n",
      "Epoch: 022, Loss: 0.5790, Val: 0.7852, Test: 0.7584\n",
      "Epoch: 023, Loss: 0.5668, Val: 0.7860, Test: 0.7576\n",
      "Epoch: 024, Loss: 0.5702, Val: 0.7848, Test: 0.7650\n",
      "Epoch: 025, Loss: 0.5696, Val: 0.7893, Test: 0.7669\n",
      "Epoch: 026, Loss: 0.5580, Val: 0.7957, Test: 0.7701\n",
      "Epoch: 027, Loss: 0.5552, Val: 0.8007, Test: 0.7791\n",
      "Epoch: 028, Loss: 0.5541, Val: 0.8095, Test: 0.7890\n",
      "Epoch: 029, Loss: 0.5460, Val: 0.8213, Test: 0.7981\n",
      "Epoch: 030, Loss: 0.5369, Val: 0.8302, Test: 0.8084\n",
      "Epoch: 031, Loss: 0.5329, Val: 0.8441, Test: 0.8269\n",
      "Epoch: 032, Loss: 0.5280, Val: 0.8562, Test: 0.8422\n",
      "Epoch: 033, Loss: 0.5219, Val: 0.8614, Test: 0.8500\n",
      "Epoch: 034, Loss: 0.5167, Val: 0.8639, Test: 0.8533\n",
      "Epoch: 035, Loss: 0.4996, Val: 0.8636, Test: 0.8537\n",
      "Epoch: 036, Loss: 0.5076, Val: 0.8647, Test: 0.8566\n",
      "Epoch: 037, Loss: 0.5070, Val: 0.8638, Test: 0.8581\n",
      "Epoch: 038, Loss: 0.5009, Val: 0.8699, Test: 0.8638\n",
      "Epoch: 039, Loss: 0.4978, Val: 0.8790, Test: 0.8738\n",
      "Epoch: 040, Loss: 0.4914, Val: 0.8876, Test: 0.8832\n",
      "Epoch: 041, Loss: 0.4830, Val: 0.8948, Test: 0.8911\n",
      "Epoch: 042, Loss: 0.4730, Val: 0.9013, Test: 0.8961\n",
      "Epoch: 043, Loss: 0.4687, Val: 0.9071, Test: 0.9004\n",
      "Epoch: 044, Loss: 0.4658, Val: 0.9127, Test: 0.9046\n",
      "Epoch: 045, Loss: 0.4723, Val: 0.9162, Test: 0.9071\n",
      "Epoch: 046, Loss: 0.4605, Val: 0.9181, Test: 0.9081\n",
      "Epoch: 047, Loss: 0.4582, Val: 0.9194, Test: 0.9074\n",
      "Epoch: 048, Loss: 0.4659, Val: 0.9200, Test: 0.9071\n",
      "Epoch: 049, Loss: 0.4623, Val: 0.9209, Test: 0.9082\n",
      "Epoch: 050, Loss: 0.4701, Val: 0.9209, Test: 0.9100\n",
      "Epoch: 051, Loss: 0.4682, Val: 0.9199, Test: 0.9111\n",
      "Epoch: 052, Loss: 0.4626, Val: 0.9191, Test: 0.9103\n",
      "Epoch: 053, Loss: 0.4618, Val: 0.9173, Test: 0.9089\n",
      "Epoch: 054, Loss: 0.4599, Val: 0.9149, Test: 0.9056\n",
      "Epoch: 055, Loss: 0.4624, Val: 0.9136, Test: 0.9053\n",
      "Epoch: 056, Loss: 0.4538, Val: 0.9124, Test: 0.9055\n",
      "Epoch: 057, Loss: 0.4594, Val: 0.9112, Test: 0.9055\n",
      "Epoch: 058, Loss: 0.4585, Val: 0.9111, Test: 0.9048\n",
      "Epoch: 059, Loss: 0.4592, Val: 0.9124, Test: 0.9056\n",
      "Epoch: 060, Loss: 0.4523, Val: 0.9127, Test: 0.9068\n",
      "Epoch: 061, Loss: 0.4565, Val: 0.9141, Test: 0.9074\n",
      "Epoch: 062, Loss: 0.4553, Val: 0.9149, Test: 0.9076\n",
      "Epoch: 063, Loss: 0.4491, Val: 0.9162, Test: 0.9072\n",
      "Epoch: 064, Loss: 0.4547, Val: 0.9175, Test: 0.9086\n",
      "Epoch: 065, Loss: 0.4551, Val: 0.9182, Test: 0.9094\n",
      "Epoch: 066, Loss: 0.4559, Val: 0.9189, Test: 0.9092\n",
      "Epoch: 067, Loss: 0.4478, Val: 0.9187, Test: 0.9086\n",
      "Epoch: 068, Loss: 0.4548, Val: 0.9188, Test: 0.9085\n",
      "Epoch: 069, Loss: 0.4533, Val: 0.9197, Test: 0.9096\n",
      "Epoch: 070, Loss: 0.4540, Val: 0.9202, Test: 0.9113\n",
      "Epoch: 071, Loss: 0.4484, Val: 0.9202, Test: 0.9125\n",
      "Epoch: 072, Loss: 0.4495, Val: 0.9202, Test: 0.9126\n",
      "Epoch: 073, Loss: 0.4477, Val: 0.9195, Test: 0.9110\n",
      "Epoch: 074, Loss: 0.4520, Val: 0.9193, Test: 0.9102\n",
      "Epoch: 075, Loss: 0.4450, Val: 0.9200, Test: 0.9119\n",
      "Epoch: 076, Loss: 0.4395, Val: 0.9202, Test: 0.9134\n",
      "Epoch: 077, Loss: 0.4453, Val: 0.9199, Test: 0.9136\n",
      "Epoch: 078, Loss: 0.4530, Val: 0.9201, Test: 0.9132\n",
      "Epoch: 079, Loss: 0.4474, Val: 0.9200, Test: 0.9124\n",
      "Epoch: 080, Loss: 0.4445, Val: 0.9211, Test: 0.9127\n",
      "Epoch: 081, Loss: 0.4510, Val: 0.9216, Test: 0.9135\n",
      "Epoch: 082, Loss: 0.4487, Val: 0.9225, Test: 0.9142\n",
      "Epoch: 083, Loss: 0.4425, Val: 0.9232, Test: 0.9142\n",
      "Epoch: 084, Loss: 0.4448, Val: 0.9246, Test: 0.9144\n",
      "Epoch: 085, Loss: 0.4395, Val: 0.9252, Test: 0.9150\n",
      "Epoch: 086, Loss: 0.4429, Val: 0.9253, Test: 0.9160\n",
      "Epoch: 087, Loss: 0.4464, Val: 0.9258, Test: 0.9169\n",
      "Epoch: 088, Loss: 0.4387, Val: 0.9265, Test: 0.9169\n",
      "Epoch: 089, Loss: 0.4412, Val: 0.9265, Test: 0.9170\n",
      "Epoch: 090, Loss: 0.4485, Val: 0.9258, Test: 0.9177\n",
      "Epoch: 091, Loss: 0.4401, Val: 0.9248, Test: 0.9171\n",
      "Epoch: 092, Loss: 0.4360, Val: 0.9253, Test: 0.9170\n",
      "Epoch: 093, Loss: 0.4326, Val: 0.9261, Test: 0.9175\n",
      "Epoch: 094, Loss: 0.4410, Val: 0.9261, Test: 0.9174\n",
      "Epoch: 095, Loss: 0.4320, Val: 0.9262, Test: 0.9171\n",
      "Epoch: 096, Loss: 0.4436, Val: 0.9255, Test: 0.9162\n",
      "Epoch: 097, Loss: 0.4369, Val: 0.9254, Test: 0.9159\n",
      "Epoch: 098, Loss: 0.4343, Val: 0.9261, Test: 0.9159\n",
      "Epoch: 099, Loss: 0.4331, Val: 0.9262, Test: 0.9154\n",
      "Epoch: 100, Loss: 0.4374, Val: 0.9256, Test: 0.9148\n",
      "Final Test: 0.9169\n"
     ]
    }
   ],
   "source": [
    "import os.path as osp\n",
    "\n",
    "import torch\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.utils import negative_sampling\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "transform = T.Compose([\n",
    "    T.NormalizeFeatures(),\n",
    "    T.ToDevice(device),\n",
    "    T.RandomLinkSplit(num_val=0.05, num_test=0.1, is_undirected=True,\n",
    "                      add_negative_train_samples=False),\n",
    "])\n",
    "\n",
    "dataset = Planetoid(\"./\", name='Cora', transform=transform)\n",
    "# After applying the `RandomLinkSplit` transform, the data is transformed from\n",
    "# a data object to a list of tuples (train_data, val_data, test_data), with\n",
    "# each element representing the corresponding split.\n",
    "train_data, val_data, test_data = dataset[0]\n",
    "\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, out_channels)\n",
    "\n",
    "    def encode(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        return self.conv2(x, edge_index)\n",
    "\n",
    "    def decode(self, z, edge_label_index):\n",
    "        return (z[edge_label_index[0]] * z[edge_label_index[1]]).sum(dim=-1)\n",
    "\n",
    "    def decode_all(self, z):\n",
    "        prob_adj = z @ z.t()\n",
    "        return (prob_adj > 0).nonzero(as_tuple=False).t()\n",
    "\n",
    "\n",
    "model = Net(dataset.num_features, 128, 64).to(device)\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    z = model.encode(train_data.x, train_data.edge_index)\n",
    "\n",
    "    # We perform a new round of negative sampling for every training epoch:\n",
    "    neg_edge_index = negative_sampling(\n",
    "        edge_index=train_data.edge_index, num_nodes=train_data.num_nodes,\n",
    "        num_neg_samples=train_data.edge_label_index.size(1), method='sparse')\n",
    "\n",
    "    edge_label_index = torch.cat(\n",
    "        [train_data.edge_label_index, neg_edge_index],\n",
    "        dim=-1,\n",
    "    )\n",
    "    edge_label = torch.cat([\n",
    "        train_data.edge_label,\n",
    "        train_data.edge_label.new_zeros(neg_edge_index.size(1))\n",
    "    ], dim=0)\n",
    "\n",
    "    out = model.decode(z, edge_label_index).view(-1)\n",
    "    loss = criterion(out, edge_label)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(data):\n",
    "    model.eval()\n",
    "    z = model.encode(data.x, data.edge_index)\n",
    "    out = model.decode(z, data.edge_label_index).view(-1).sigmoid()\n",
    "    return roc_auc_score(data.edge_label.cpu().numpy(), out.cpu().numpy())\n",
    "\n",
    "\n",
    "best_val_auc = final_test_auc = 0\n",
    "for epoch in range(1, 101):\n",
    "    loss = train()\n",
    "    val_auc = test(val_data)\n",
    "    test_auc = test(test_data)\n",
    "    if val_auc > best_val_auc:\n",
    "        best_val_auc = val_auc\n",
    "        final_test_auc = test_auc\n",
    "    print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Val: {val_auc:.4f}, '\n",
    "          f'Test: {test_auc:.4f}')\n",
    "\n",
    "print(f'Final Test: {final_test_auc:.4f}')\n",
    "\n",
    "z = model.encode(test_data.x, test_data.edge_index)\n",
    "final_edge_index = model.decode_all(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Link Prediction on Senators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.,  0.,  0.,  0.],\n",
      "        [ 0., -1.,  0.,  0.],\n",
      "        [ 0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0., -1.]])\n",
      "Iteraciones:  100\n",
      "Loss:  tensor(49.1557)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch_geometric.utils import stochastic_blockmodel_graph, to_dense_adj\n",
    "from graspologic.embed import AdjacencySpectralEmbed \n",
    "from models.RDPG_GD import GRDPG_GD_Armijo\n",
    "from models.GLASE_unshared_normalized import gLASE \n",
    "# from models.GLASE_unshared_normalized_v2 import gLASE_v2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "d = 4\n",
    "n_P1 = 100\n",
    "n_P2 = 80\n",
    "n_L1 = 100\n",
    "n_L2 = 100\n",
    "n_L3 = 30\n",
    "\n",
    "P1_L1 = 0.9\n",
    "P1_L2 = 0.01\n",
    "P1_L3 = 0.2  \n",
    "P2_L1 = 0.1\n",
    "P2_L2 = 0.8\n",
    "P2_L3 = 0.3\n",
    "\n",
    "\n",
    "p = [\n",
    "    [0, 0, P1_L1, P1_L2, P1_L3],\n",
    "    [0, 0, P2_L1, P2_L2, P2_L3],\n",
    "    [P1_L1, P2_L1, 0, 0, 0], \n",
    "    [P1_L2, P2_L2, 0, 0, 0], \n",
    "    [P1_L3, P2_L3, 0, 0, 0]\n",
    "    ]\n",
    "\n",
    "n = [n_P1, n_P2, n_L1, n_L2, n_L3]\n",
    "\n",
    "num_nodes = np.sum(n)\n",
    "edge_index = stochastic_blockmodel_graph(n, p)\n",
    "\n",
    "\n",
    "## MASK\n",
    "n_P1_np = 80\n",
    "n_P2_np = 60\n",
    "senadores_no_presentes = list(range(n_P1_np)) + list(range(n_P1,n_P1+n_P2_np))\n",
    "\n",
    "mask = torch.ones([num_nodes,num_nodes]).squeeze(0)\n",
    "for i in senadores_no_presentes:\n",
    "    votos = (torch.rand(1, num_nodes) < 0.1).int()\n",
    "    mask[i,:] = votos\n",
    "    mask[:,i] = votos\n",
    "\n",
    "\n",
    "## ASE \n",
    "adj_matrix = to_dense_adj(edge_index.to('cpu')).squeeze(0)\n",
    "ase = AdjacencySpectralEmbed(n_components=d, diag_aug=True, algorithm='full')\n",
    "masked_adj = adj_matrix*mask\n",
    "x_ase = ase.fit_transform(masked_adj.numpy())\n",
    "x_ase = torch.from_numpy(x_ase)\n",
    "\n",
    "A = to_dense_adj(edge_index.to('cpu'), max_num_nodes=num_nodes).squeeze(0)\n",
    "\n",
    "u, V = torch.linalg.eig(A)\n",
    "\n",
    "list_q=[]\n",
    "for i in range(d):\n",
    "    if u[i].numpy()>0:\n",
    "        list_q.append(1)\n",
    "    else:\n",
    "        list_q.append(-1)\n",
    "        \n",
    "# list_q.sort(reverse=True)\n",
    "q = torch.Tensor(list_q)\n",
    "Q=torch.diag(q)\n",
    "\n",
    "print(Q)\n",
    "\n",
    "\n",
    "torch.norm((x_ase@Q@x_ase.T - to_dense_adj(edge_index).squeeze(0))*mask)\n",
    "\n",
    "\n",
    "x_grdpg, cost, k  = GRDPG_GD_Armijo(x_ase, edge_index, Q, mask.nonzero().t().contiguous())\n",
    "x_grdpg = x_grdpg.detach()\n",
    "print(\"Iteraciones: \", k)\n",
    "print(\"Loss: \", torch.norm((x_grdpg@Q@x_grdpg.T - to_dense_adj(edge_index).squeeze(0))*to_dense_adj(mask.nonzero().t().contiguous()).squeeze(0)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(63.5190, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor(51.3135, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor(50.3738, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor(50.3378, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor(50.2794, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor(50.3385, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor(50.1427, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor(50.2505, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor(50.2009, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor(50.1332, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    }
   ],
   "source": [
    "gd_steps = 10\n",
    "lr = 1e-2\n",
    "device = 'cuda'\n",
    "model = gLASE(d,d, gd_steps)\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "epochs = 1000\n",
    "\n",
    "## Initialization\n",
    "for step in range(gd_steps):\n",
    "    model.gd[step].lin1.weight.data = (torch.eye(d,d)*lr).to(device)#torch.nn.init.xavier_uniform_(model.gd[step].lin1.weight)*lr\n",
    "    model.gd[step].lin2.weight.data = (torch.eye(d,d)*lr).to(device)#torch.nn.init.xavier_uniform_(model.gd[step].lin2.weight)*lr\n",
    "    \n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "# Define ATT mask\n",
    "edge_index_2 = torch.ones([num_nodes,num_nodes],).nonzero().t().contiguous().to(device)\n",
    "mask = mask.to(device)\n",
    "x_ase = x_ase.to(device)\n",
    "edge_index = edge_index.to(device)\n",
    "Q = Q.to(device)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # Train\n",
    "    model.train()\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    out = model(x_ase, edge_index, edge_index_2, Q, mask.nonzero().t().contiguous())\n",
    "    loss = torch.norm((out@Q@out.T - to_dense_adj(edge_index).squeeze(0))*mask)\n",
    "    loss.backward() \n",
    "    optimizer.step() \n",
    "\n",
    "    if epoch % 100 ==0:\n",
    "        print(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(50.0269, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss = torch.norm((out@Q@out.T - to_dense_adj(edge_index).squeeze(0))*mask)\n",
    "print(loss)\n",
    "x_glase = out.detach().to('cpu')\n",
    "x_ase = x_ase.to('cpu')\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize =(15,5))\n",
    "axes[0].scatter(x_ase[n_P1_np:n_P1,0],x_ase[n_P1_np:n_P1,2], c='royalblue',marker='o',label='Party 1')\n",
    "axes[0].scatter(x_ase[:n_P1_np,0],x_ase[:n_P1_np,2], c='gold',marker='X',label='Not present (Party 1)')\n",
    "axes[0].scatter(x_ase[n_P1+n_P2_np:n_P1+n_P2,0],x_ase[n_P1+n_P2_np:n_P1+n_P2,2], c='firebrick',marker='o',label='Party 2')\n",
    "axes[0].scatter(x_ase[n_P1:n_P1+n_P2_np,0],x_ase[n_P1:n_P1+n_P2_np,2], c='limegreen',marker='X',label='Not present (Party 2)')\n",
    "axes[0].scatter(x_ase[n_P1+n_P2:n_P1+n_P2+n_L1,0],x_ase[n_P1+n_P2:n_P1+n_P2+n_L1,2], c='cornflowerblue',marker='^',label='Party 1 laws')\n",
    "axes[0].scatter(x_ase[n_P1+n_P2+n_L1:n_P1+n_P2+n_L1+n_L2,0],x_ase[n_P1+n_P2+n_L1:n_P1+n_P2+n_L1+n_L2,2],c='indianred',marker='^',label='Party 2 laws')\n",
    "axes[0].scatter(x_ase[n_P1+n_P2+n_L1+n_L2:,0],x_ase[n_P1+n_P2+n_L1+n_L2:,2],c='darkorange',marker='^',label='Bipartisan laws')\n",
    "axes[0].set_title('ASE')\n",
    "\n",
    "axes[1].scatter(x_grdpg[n_P1_np:n_P1,0],x_grdpg[n_P1_np:n_P1,2], c='royalblue',marker='o',label='Party 1')\n",
    "axes[1].scatter(x_grdpg[:n_P1_np,0],x_grdpg[:n_P1_np,2], c='gold',marker='X',label='Not present (Party 1)')\n",
    "axes[1].scatter(x_grdpg[n_P1+n_P2_np:n_P1+n_P2,0],x_grdpg[n_P1+n_P2_np:n_P1+n_P2,2], c='firebrick',marker='o',label='Party 2')\n",
    "axes[1].scatter(x_grdpg[n_P1:n_P1+n_P2_np,0],x_grdpg[n_P1:n_P1+n_P2_np,2], c='limegreen',marker='X',label='Not present (Party 2)')\n",
    "axes[1].scatter(x_grdpg[n_P1+n_P2:n_P1+n_P2+n_L1,0],x_grdpg[n_P1+n_P2:n_P1+n_P2+n_L1,2], c='cornflowerblue',marker='^',label='Party 1 laws')\n",
    "axes[1].scatter(x_grdpg[n_P1+n_P2+n_L1:n_P1+n_P2+n_L1+n_L2,0],x_grdpg[n_P1+n_P2+n_L1:n_P1+n_P2+n_L1+n_L2,2],c='indianred',marker='^',label='Party 2 laws')\n",
    "axes[1].scatter(x_grdpg[n_P1+n_P2+n_L1+n_L2:,0],x_grdpg[n_P1+n_P2+n_L1+n_L2:,2],c='darkorange',marker='^',label='Bipartisan laws')\n",
    "axes[1].set_title('GD')\n",
    "\n",
    "axes[2].scatter(x_glase[n_P1_np:n_P1,0],x_glase[n_P1_np:n_P1,2], c='royalblue',marker='o',label='Party 1')\n",
    "axes[2].scatter(x_glase[:n_P1_np,0],x_glase[:n_P1_np,2], c='gold',marker='X',label='Not present (Party 1)')\n",
    "axes[2].scatter(x_glase[n_P1+n_P2_np:n_P1+n_P2,0],x_glase[n_P1+n_P2_np:n_P1+n_P2,2], c='firebrick',marker='o',label='Party 2')\n",
    "axes[2].scatter(x_glase[n_P1:n_P1+n_P2_np,0],x_glase[n_P1:n_P1+n_P2_np,2], c='limegreen',marker='X',label='Not present (Party 2)')\n",
    "axes[2].scatter(x_glase[n_P1+n_P2:n_P1+n_P2+n_L1,0],x_glase[n_P1+n_P2:n_P1+n_P2+n_L1,2], c='cornflowerblue',marker='^',label='Party 1 laws')\n",
    "axes[2].scatter(x_glase[n_P1+n_P2+n_L1:n_P1+n_P2+n_L1+n_L2,0],x_glase[n_P1+n_P2+n_L1:n_P1+n_P2+n_L1+n_L2,2],c='indianred',marker='^',label='Party 2 laws')\n",
    "axes[2].scatter(x_glase[n_P1+n_P2+n_L1+n_L2:,0],x_glase[n_P1+n_P2+n_L1+n_L2:,2],c='darkorange',marker='^',label='Bipartisan laws')\n",
    "axes[2].set_title('LASE')\n",
    "plt.legend(loc='upper center', bbox_to_anchor=(-1, -0.07),fancybox=True, shadow=True, ncol=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([410, 5])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Node features -- One hot encoding of label P1, P2, L1, L2, L3\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "labels = np.concatenate((np.ones(n_P1)*0,np.ones(n_P2), np.ones(n_L1)*2, np.ones(n_L2)*3, np.ones(n_L3)*4))\n",
    "labels = labels.tolist()\n",
    "labels = torch.tensor(labels).long()\n",
    "labels = F.one_hot(labels)\n",
    "\n",
    "\n",
    "\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Split Train, Val, Test\n",
    "from torch_geometric.data import Data\n",
    "import torch_geometric.transforms as T\n",
    "\n",
    "device = 'cuda'\n",
    "\n",
    "masked_edge_index = masked_adj.nonzero().t().contiguous()\n",
    "\n",
    "data = Data(x=labels.float(), x_ase=x_ase, x_glase=x_glase, edge_index=masked_edge_index)\n",
    "\n",
    "transform = T.Compose([\n",
    "    # T.NormalizeFeatures(),\n",
    "    T.ToDevice(device),\n",
    "    T.RandomLinkSplit(num_val=0.05, num_test=0.1, is_undirected=True,\n",
    "                      add_negative_train_samples=False),\n",
    "])\n",
    "\n",
    "\n",
    "train_data, val_data, test_data = transform(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GCN embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.6929, Val: 0.9109, Test: 0.8962\n",
      "Epoch: 002, Loss: 0.6478, Val: 0.9019, Test: 0.8843\n",
      "Epoch: 003, Loss: 0.6156, Val: 0.8797, Test: 0.8647\n",
      "Epoch: 004, Loss: 0.5787, Val: 0.8749, Test: 0.8593\n",
      "Epoch: 005, Loss: 0.5600, Val: 0.8679, Test: 0.8514\n",
      "Epoch: 006, Loss: 0.5605, Val: 0.8743, Test: 0.8544\n",
      "Epoch: 007, Loss: 0.5578, Val: 0.8743, Test: 0.8550\n",
      "Epoch: 008, Loss: 0.5525, Val: 0.8749, Test: 0.8539\n",
      "Epoch: 009, Loss: 0.5431, Val: 0.8783, Test: 0.8548\n",
      "Epoch: 010, Loss: 0.5413, Val: 0.8799, Test: 0.8563\n",
      "Epoch: 011, Loss: 0.5432, Val: 0.8802, Test: 0.8560\n",
      "Epoch: 012, Loss: 0.5417, Val: 0.8797, Test: 0.8549\n",
      "Epoch: 013, Loss: 0.5385, Val: 0.8801, Test: 0.8561\n",
      "Epoch: 014, Loss: 0.5393, Val: 0.8794, Test: 0.8570\n",
      "Epoch: 015, Loss: 0.5390, Val: 0.8795, Test: 0.8571\n",
      "Epoch: 016, Loss: 0.5385, Val: 0.8787, Test: 0.8565\n",
      "Epoch: 017, Loss: 0.5346, Val: 0.8772, Test: 0.8560\n",
      "Epoch: 018, Loss: 0.5390, Val: 0.8771, Test: 0.8560\n",
      "Epoch: 019, Loss: 0.5334, Val: 0.8769, Test: 0.8562\n",
      "Epoch: 020, Loss: 0.5331, Val: 0.8770, Test: 0.8558\n",
      "Epoch: 021, Loss: 0.5380, Val: 0.8774, Test: 0.8554\n",
      "Epoch: 022, Loss: 0.5353, Val: 0.8778, Test: 0.8553\n",
      "Epoch: 023, Loss: 0.5301, Val: 0.8779, Test: 0.8555\n",
      "Epoch: 024, Loss: 0.5404, Val: 0.8775, Test: 0.8561\n",
      "Epoch: 025, Loss: 0.5368, Val: 0.8776, Test: 0.8565\n",
      "Epoch: 026, Loss: 0.5398, Val: 0.8781, Test: 0.8561\n",
      "Epoch: 027, Loss: 0.5317, Val: 0.8784, Test: 0.8563\n",
      "Epoch: 028, Loss: 0.5440, Val: 0.8778, Test: 0.8562\n",
      "Epoch: 029, Loss: 0.5438, Val: 0.8773, Test: 0.8578\n",
      "Epoch: 030, Loss: 0.5330, Val: 0.8770, Test: 0.8583\n",
      "Epoch: 031, Loss: 0.5298, Val: 0.8772, Test: 0.8581\n",
      "Epoch: 032, Loss: 0.5288, Val: 0.8772, Test: 0.8573\n",
      "Epoch: 033, Loss: 0.5283, Val: 0.8778, Test: 0.8561\n",
      "Epoch: 034, Loss: 0.5362, Val: 0.8791, Test: 0.8563\n",
      "Epoch: 035, Loss: 0.5446, Val: 0.8793, Test: 0.8563\n",
      "Epoch: 036, Loss: 0.5361, Val: 0.8795, Test: 0.8561\n",
      "Epoch: 037, Loss: 0.5354, Val: 0.8789, Test: 0.8562\n",
      "Epoch: 038, Loss: 0.5362, Val: 0.8789, Test: 0.8560\n",
      "Epoch: 039, Loss: 0.5233, Val: 0.8792, Test: 0.8560\n",
      "Epoch: 040, Loss: 0.5295, Val: 0.8792, Test: 0.8561\n",
      "Epoch: 041, Loss: 0.5296, Val: 0.8790, Test: 0.8563\n",
      "Epoch: 042, Loss: 0.5384, Val: 0.8781, Test: 0.8561\n",
      "Epoch: 043, Loss: 0.5328, Val: 0.8775, Test: 0.8569\n",
      "Epoch: 044, Loss: 0.5279, Val: 0.8778, Test: 0.8576\n",
      "Epoch: 045, Loss: 0.5342, Val: 0.8779, Test: 0.8579\n",
      "Epoch: 046, Loss: 0.5330, Val: 0.8775, Test: 0.8575\n",
      "Epoch: 047, Loss: 0.5288, Val: 0.8782, Test: 0.8564\n",
      "Epoch: 048, Loss: 0.5269, Val: 0.8791, Test: 0.8565\n",
      "Epoch: 049, Loss: 0.5424, Val: 0.8788, Test: 0.8567\n",
      "Epoch: 050, Loss: 0.5304, Val: 0.8789, Test: 0.8575\n",
      "Epoch: 051, Loss: 0.5255, Val: 0.8786, Test: 0.8582\n",
      "Epoch: 052, Loss: 0.5323, Val: 0.8790, Test: 0.8577\n",
      "Epoch: 053, Loss: 0.5257, Val: 0.8795, Test: 0.8570\n",
      "Epoch: 054, Loss: 0.5253, Val: 0.8795, Test: 0.8568\n",
      "Epoch: 055, Loss: 0.5313, Val: 0.8788, Test: 0.8577\n",
      "Epoch: 056, Loss: 0.5347, Val: 0.8786, Test: 0.8580\n",
      "Epoch: 057, Loss: 0.5330, Val: 0.8785, Test: 0.8572\n",
      "Epoch: 058, Loss: 0.5198, Val: 0.8787, Test: 0.8574\n",
      "Epoch: 059, Loss: 0.5309, Val: 0.8786, Test: 0.8579\n",
      "Epoch: 060, Loss: 0.5324, Val: 0.8786, Test: 0.8581\n",
      "Epoch: 061, Loss: 0.5370, Val: 0.8786, Test: 0.8583\n",
      "Epoch: 062, Loss: 0.5334, Val: 0.8787, Test: 0.8580\n",
      "Epoch: 063, Loss: 0.5297, Val: 0.8788, Test: 0.8580\n",
      "Epoch: 064, Loss: 0.5295, Val: 0.8795, Test: 0.8580\n",
      "Epoch: 065, Loss: 0.5334, Val: 0.8796, Test: 0.8591\n",
      "Epoch: 066, Loss: 0.5301, Val: 0.8798, Test: 0.8596\n",
      "Epoch: 067, Loss: 0.5228, Val: 0.8799, Test: 0.8594\n",
      "Epoch: 068, Loss: 0.5310, Val: 0.8797, Test: 0.8588\n",
      "Epoch: 069, Loss: 0.5240, Val: 0.8799, Test: 0.8585\n",
      "Epoch: 070, Loss: 0.5256, Val: 0.8801, Test: 0.8597\n",
      "Epoch: 071, Loss: 0.5287, Val: 0.8802, Test: 0.8599\n",
      "Epoch: 072, Loss: 0.5340, Val: 0.8802, Test: 0.8596\n",
      "Epoch: 073, Loss: 0.5312, Val: 0.8802, Test: 0.8588\n",
      "Epoch: 074, Loss: 0.5283, Val: 0.8804, Test: 0.8590\n",
      "Epoch: 075, Loss: 0.5266, Val: 0.8805, Test: 0.8608\n",
      "Epoch: 076, Loss: 0.5257, Val: 0.8809, Test: 0.8616\n",
      "Epoch: 077, Loss: 0.5262, Val: 0.8805, Test: 0.8614\n",
      "Epoch: 078, Loss: 0.5240, Val: 0.8802, Test: 0.8601\n",
      "Epoch: 079, Loss: 0.5280, Val: 0.8799, Test: 0.8596\n",
      "Epoch: 080, Loss: 0.5261, Val: 0.8802, Test: 0.8598\n",
      "Epoch: 081, Loss: 0.5272, Val: 0.8806, Test: 0.8608\n",
      "Epoch: 082, Loss: 0.5239, Val: 0.8813, Test: 0.8615\n",
      "Epoch: 083, Loss: 0.5284, Val: 0.8819, Test: 0.8616\n",
      "Epoch: 084, Loss: 0.5298, Val: 0.8813, Test: 0.8608\n",
      "Epoch: 085, Loss: 0.5289, Val: 0.8816, Test: 0.8620\n",
      "Epoch: 086, Loss: 0.5285, Val: 0.8808, Test: 0.8625\n",
      "Epoch: 087, Loss: 0.5351, Val: 0.8810, Test: 0.8617\n",
      "Epoch: 088, Loss: 0.5304, Val: 0.8809, Test: 0.8614\n",
      "Epoch: 089, Loss: 0.5308, Val: 0.8812, Test: 0.8624\n",
      "Epoch: 090, Loss: 0.5197, Val: 0.8814, Test: 0.8636\n",
      "Epoch: 091, Loss: 0.5223, Val: 0.8808, Test: 0.8636\n",
      "Epoch: 092, Loss: 0.5203, Val: 0.8813, Test: 0.8628\n",
      "Epoch: 093, Loss: 0.5155, Val: 0.8808, Test: 0.8612\n",
      "Epoch: 094, Loss: 0.5307, Val: 0.8810, Test: 0.8610\n",
      "Epoch: 095, Loss: 0.5235, Val: 0.8822, Test: 0.8622\n",
      "Epoch: 096, Loss: 0.5166, Val: 0.8829, Test: 0.8636\n",
      "Epoch: 097, Loss: 0.5228, Val: 0.8841, Test: 0.8630\n",
      "Epoch: 098, Loss: 0.5282, Val: 0.8832, Test: 0.8619\n",
      "Epoch: 099, Loss: 0.5355, Val: 0.8827, Test: 0.8621\n",
      "Epoch: 100, Loss: 0.5212, Val: 0.8806, Test: 0.8618\n",
      "Final Test: 0.8962\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.nn import GCNConv\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from torch_geometric.utils import negative_sampling\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, out_channels)\n",
    "\n",
    "    def encode(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        return self.conv2(x, edge_index)\n",
    "\n",
    "    def decode(self, z, edge_label_index):\n",
    "        return (z[edge_label_index[0]] * z[edge_label_index[1]]).sum(dim=-1)\n",
    "\n",
    "    def decode_all(self, z):\n",
    "        prob_adj = z @ z.t()\n",
    "        return (prob_adj > 0).nonzero(as_tuple=False).t()\n",
    "\n",
    "\n",
    "model = Net(5, 128, 64).to(device)\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    z = model.encode(train_data.x, train_data.edge_index)\n",
    "\n",
    "    # We perform a new round of negative sampling for every training epoch:\n",
    "    neg_edge_index = negative_sampling(\n",
    "        edge_index=train_data.edge_index, num_nodes=train_data.num_nodes,\n",
    "        num_neg_samples=train_data.edge_label_index.size(1), method='sparse')\n",
    "\n",
    "    edge_label_index = torch.cat(\n",
    "        [train_data.edge_label_index, neg_edge_index],\n",
    "        dim=-1,\n",
    "    )\n",
    "    edge_label = torch.cat([\n",
    "        train_data.edge_label,\n",
    "        train_data.edge_label.new_zeros(neg_edge_index.size(1))\n",
    "    ], dim=0)\n",
    "\n",
    "    out = model.decode(z, edge_label_index).view(-1)\n",
    "    loss = criterion(out, edge_label)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(data):\n",
    "    model.eval()\n",
    "    z = model.encode(data.x, data.edge_index)\n",
    "    out = model.decode(z, data.edge_label_index).view(-1).sigmoid()\n",
    "    return roc_auc_score(data.edge_label.cpu().numpy(), out.cpu().numpy())\n",
    "\n",
    "\n",
    "best_val_auc = final_test_auc = 0\n",
    "for epoch in range(1, 101):\n",
    "    loss = train()\n",
    "    val_auc = test(val_data)\n",
    "    test_auc = test(test_data)\n",
    "    if val_auc > best_val_auc:\n",
    "        best_val_auc = val_auc\n",
    "        final_test_auc = test_auc\n",
    "    print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Val: {val_auc:.4f}, '\n",
    "          f'Test: {test_auc:.4f}')\n",
    "\n",
    "print(f'Final Test: {final_test_auc:.4f}')\n",
    "\n",
    "z = model.encode(test_data.x, test_data.edge_index)\n",
    "final_edge_index = model.decode_all(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Predict on entire masked graph\n",
    "\n",
    "z = model.encode(data.x, data.edge_index)\n",
    "final_edge_index = model.decode_all(z)\n",
    "\n",
    "\n",
    "predicted_adj = to_dense_adj(final_edge_index).squeeze(0).to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "        [1., 1., 1.,  ..., 0., 0., 0.],\n",
       "        [0., 1., 1.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 1.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_matrix[senadores_no_presentes][:,n_P1+n_P2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([48, 230])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_matrix[senadores_no_presentes][:,n_P1+n_P2:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8604)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(adj_matrix[senadores_no_presentes][:,n_P1+n_P2:]==predicted_adj[senadores_no_presentes][:,n_P1+n_P2:]).sum() / 48 / 230"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ASE embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.6901, Val: 0.8946, Test: 0.8835\n",
      "Epoch: 002, Loss: 0.6330, Val: 0.8840, Test: 0.8689\n",
      "Epoch: 003, Loss: 0.5941, Val: 0.8782, Test: 0.8613\n",
      "Epoch: 004, Loss: 0.5537, Val: 0.8779, Test: 0.8574\n",
      "Epoch: 005, Loss: 0.5509, Val: 0.8788, Test: 0.8562\n",
      "Epoch: 006, Loss: 0.5619, Val: 0.8800, Test: 0.8563\n",
      "Epoch: 007, Loss: 0.5363, Val: 0.8796, Test: 0.8552\n",
      "Epoch: 008, Loss: 0.5334, Val: 0.8782, Test: 0.8540\n",
      "Epoch: 009, Loss: 0.5376, Val: 0.8797, Test: 0.8558\n",
      "Epoch: 010, Loss: 0.5494, Val: 0.8797, Test: 0.8570\n",
      "Epoch: 011, Loss: 0.5422, Val: 0.8789, Test: 0.8572\n",
      "Epoch: 012, Loss: 0.5431, Val: 0.8784, Test: 0.8570\n",
      "Epoch: 013, Loss: 0.5417, Val: 0.8780, Test: 0.8573\n",
      "Epoch: 014, Loss: 0.5347, Val: 0.8786, Test: 0.8566\n",
      "Epoch: 015, Loss: 0.5312, Val: 0.8794, Test: 0.8560\n",
      "Epoch: 016, Loss: 0.5382, Val: 0.8796, Test: 0.8557\n",
      "Epoch: 017, Loss: 0.5344, Val: 0.8797, Test: 0.8557\n",
      "Epoch: 018, Loss: 0.5309, Val: 0.8791, Test: 0.8561\n",
      "Epoch: 019, Loss: 0.5350, Val: 0.8791, Test: 0.8569\n",
      "Epoch: 020, Loss: 0.5313, Val: 0.8788, Test: 0.8584\n",
      "Epoch: 021, Loss: 0.5382, Val: 0.8785, Test: 0.8589\n",
      "Epoch: 022, Loss: 0.5361, Val: 0.8787, Test: 0.8581\n",
      "Epoch: 023, Loss: 0.5350, Val: 0.8790, Test: 0.8587\n",
      "Epoch: 024, Loss: 0.5335, Val: 0.8791, Test: 0.8582\n",
      "Epoch: 025, Loss: 0.5298, Val: 0.8792, Test: 0.8574\n",
      "Epoch: 026, Loss: 0.5220, Val: 0.8800, Test: 0.8566\n",
      "Epoch: 027, Loss: 0.5341, Val: 0.8804, Test: 0.8565\n",
      "Epoch: 028, Loss: 0.5307, Val: 0.8806, Test: 0.8567\n",
      "Epoch: 029, Loss: 0.5305, Val: 0.8801, Test: 0.8566\n",
      "Epoch: 030, Loss: 0.5306, Val: 0.8786, Test: 0.8582\n",
      "Epoch: 031, Loss: 0.5318, Val: 0.8788, Test: 0.8584\n",
      "Epoch: 032, Loss: 0.5314, Val: 0.8792, Test: 0.8571\n",
      "Epoch: 033, Loss: 0.5351, Val: 0.8793, Test: 0.8569\n",
      "Epoch: 034, Loss: 0.5331, Val: 0.8791, Test: 0.8572\n",
      "Epoch: 035, Loss: 0.5346, Val: 0.8790, Test: 0.8586\n",
      "Epoch: 036, Loss: 0.5275, Val: 0.8788, Test: 0.8592\n",
      "Epoch: 037, Loss: 0.5405, Val: 0.8790, Test: 0.8594\n",
      "Epoch: 038, Loss: 0.5290, Val: 0.8791, Test: 0.8596\n",
      "Epoch: 039, Loss: 0.5273, Val: 0.8791, Test: 0.8594\n",
      "Epoch: 040, Loss: 0.5312, Val: 0.8792, Test: 0.8586\n",
      "Epoch: 041, Loss: 0.5316, Val: 0.8796, Test: 0.8582\n",
      "Epoch: 042, Loss: 0.5239, Val: 0.8797, Test: 0.8591\n",
      "Epoch: 043, Loss: 0.5304, Val: 0.8796, Test: 0.8592\n",
      "Epoch: 044, Loss: 0.5356, Val: 0.8800, Test: 0.8579\n",
      "Epoch: 045, Loss: 0.5250, Val: 0.8801, Test: 0.8573\n",
      "Epoch: 046, Loss: 0.5331, Val: 0.8799, Test: 0.8573\n",
      "Epoch: 047, Loss: 0.5266, Val: 0.8797, Test: 0.8579\n",
      "Epoch: 048, Loss: 0.5247, Val: 0.8796, Test: 0.8591\n",
      "Epoch: 049, Loss: 0.5242, Val: 0.8797, Test: 0.8592\n",
      "Epoch: 050, Loss: 0.5220, Val: 0.8796, Test: 0.8584\n",
      "Epoch: 051, Loss: 0.5364, Val: 0.8795, Test: 0.8586\n",
      "Epoch: 052, Loss: 0.5300, Val: 0.8797, Test: 0.8597\n",
      "Epoch: 053, Loss: 0.5324, Val: 0.8791, Test: 0.8602\n",
      "Epoch: 054, Loss: 0.5366, Val: 0.8793, Test: 0.8604\n",
      "Epoch: 055, Loss: 0.5247, Val: 0.8798, Test: 0.8609\n",
      "Epoch: 056, Loss: 0.5284, Val: 0.8804, Test: 0.8612\n",
      "Epoch: 057, Loss: 0.5327, Val: 0.8807, Test: 0.8616\n",
      "Epoch: 058, Loss: 0.5316, Val: 0.8808, Test: 0.8614\n",
      "Epoch: 059, Loss: 0.5232, Val: 0.8807, Test: 0.8609\n",
      "Epoch: 060, Loss: 0.5294, Val: 0.8806, Test: 0.8606\n",
      "Epoch: 061, Loss: 0.5282, Val: 0.8806, Test: 0.8607\n",
      "Epoch: 062, Loss: 0.5271, Val: 0.8810, Test: 0.8612\n",
      "Epoch: 063, Loss: 0.5349, Val: 0.8814, Test: 0.8618\n",
      "Epoch: 064, Loss: 0.5271, Val: 0.8819, Test: 0.8625\n",
      "Epoch: 065, Loss: 0.5228, Val: 0.8816, Test: 0.8629\n",
      "Epoch: 066, Loss: 0.5265, Val: 0.8817, Test: 0.8624\n",
      "Epoch: 067, Loss: 0.5199, Val: 0.8810, Test: 0.8617\n",
      "Epoch: 068, Loss: 0.5170, Val: 0.8813, Test: 0.8616\n",
      "Epoch: 069, Loss: 0.5268, Val: 0.8797, Test: 0.8613\n",
      "Epoch: 070, Loss: 0.5305, Val: 0.8808, Test: 0.8618\n",
      "Epoch: 071, Loss: 0.5234, Val: 0.8807, Test: 0.8617\n",
      "Epoch: 072, Loss: 0.5255, Val: 0.8817, Test: 0.8634\n",
      "Epoch: 073, Loss: 0.5238, Val: 0.8815, Test: 0.8637\n",
      "Epoch: 074, Loss: 0.5274, Val: 0.8802, Test: 0.8629\n",
      "Epoch: 075, Loss: 0.5245, Val: 0.8800, Test: 0.8630\n",
      "Epoch: 076, Loss: 0.5143, Val: 0.8807, Test: 0.8635\n",
      "Epoch: 077, Loss: 0.5207, Val: 0.8818, Test: 0.8644\n",
      "Epoch: 078, Loss: 0.5220, Val: 0.8832, Test: 0.8646\n",
      "Epoch: 079, Loss: 0.5147, Val: 0.8836, Test: 0.8646\n",
      "Epoch: 080, Loss: 0.5251, Val: 0.8831, Test: 0.8633\n",
      "Epoch: 081, Loss: 0.5208, Val: 0.8831, Test: 0.8626\n",
      "Epoch: 082, Loss: 0.5243, Val: 0.8822, Test: 0.8635\n",
      "Epoch: 083, Loss: 0.5204, Val: 0.8799, Test: 0.8632\n",
      "Epoch: 084, Loss: 0.5232, Val: 0.8792, Test: 0.8624\n",
      "Epoch: 085, Loss: 0.5259, Val: 0.8796, Test: 0.8625\n",
      "Epoch: 086, Loss: 0.5244, Val: 0.8802, Test: 0.8629\n",
      "Epoch: 087, Loss: 0.5223, Val: 0.8809, Test: 0.8645\n",
      "Epoch: 088, Loss: 0.5291, Val: 0.8821, Test: 0.8652\n",
      "Epoch: 089, Loss: 0.5179, Val: 0.8829, Test: 0.8653\n",
      "Epoch: 090, Loss: 0.5158, Val: 0.8831, Test: 0.8645\n",
      "Epoch: 091, Loss: 0.5170, Val: 0.8834, Test: 0.8645\n",
      "Epoch: 092, Loss: 0.5143, Val: 0.8837, Test: 0.8650\n",
      "Epoch: 093, Loss: 0.5230, Val: 0.8816, Test: 0.8624\n",
      "Epoch: 094, Loss: 0.5279, Val: 0.8794, Test: 0.8613\n",
      "Epoch: 095, Loss: 0.5154, Val: 0.8801, Test: 0.8630\n",
      "Epoch: 096, Loss: 0.5202, Val: 0.8812, Test: 0.8649\n",
      "Epoch: 097, Loss: 0.5269, Val: 0.8806, Test: 0.8634\n",
      "Epoch: 098, Loss: 0.5188, Val: 0.8803, Test: 0.8618\n",
      "Epoch: 099, Loss: 0.5252, Val: 0.8811, Test: 0.8628\n",
      "Epoch: 100, Loss: 0.5159, Val: 0.8827, Test: 0.8650\n",
      "Final Test: 0.8835\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.nn import GCNConv\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from torch_geometric.utils import negative_sampling\n",
    "\n",
    "\n",
    "model = Net(9, 128, 64).to(device)\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    x_train = torch.concatenate((train_data.x, train_data.x_ase), axis=1)\n",
    "    z = model.encode(x_train, train_data.edge_index)\n",
    "\n",
    "    # We perform a new round of negative sampling for every training epoch:\n",
    "    neg_edge_index = negative_sampling(\n",
    "        edge_index=train_data.edge_index, num_nodes=train_data.num_nodes,\n",
    "        num_neg_samples=train_data.edge_label_index.size(1), method='sparse')\n",
    "\n",
    "    edge_label_index = torch.cat(\n",
    "        [train_data.edge_label_index, neg_edge_index],\n",
    "        dim=-1,\n",
    "    )\n",
    "    edge_label = torch.cat([\n",
    "        train_data.edge_label,\n",
    "        train_data.edge_label.new_zeros(neg_edge_index.size(1))\n",
    "    ], dim=0)\n",
    "\n",
    "    out = model.decode(z, edge_label_index).view(-1)\n",
    "    loss = criterion(out, edge_label)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(data):\n",
    "    model.eval()\n",
    "    x_test = torch.concatenate((data.x, data.x_ase), axis=1)\n",
    "    z = model.encode(x_test, data.edge_index)\n",
    "    out = model.decode(z, data.edge_label_index).view(-1).sigmoid()\n",
    "    return roc_auc_score(data.edge_label.cpu().numpy(), out.cpu().numpy())\n",
    "\n",
    "\n",
    "best_val_auc = final_test_auc = 0\n",
    "for epoch in range(1, 101):\n",
    "    loss = train()\n",
    "    val_auc = test(val_data)\n",
    "    test_auc = test(test_data)\n",
    "    if val_auc > best_val_auc:\n",
    "        best_val_auc = val_auc\n",
    "        final_test_auc = test_auc\n",
    "    print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Val: {val_auc:.4f}, '\n",
    "          f'Test: {test_auc:.4f}')\n",
    "\n",
    "print(f'Final Test: {final_test_auc:.4f}')\n",
    "\n",
    "x_test = torch.concatenate((test_data.x, test_data.x_ase), axis=1)\n",
    "z = model.encode(x_test, test_data.edge_index)\n",
    "final_edge_index = model.decode_all(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8276)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Predict on entire masked graph\n",
    "x_test = torch.concatenate((data.x, data.x_ase), axis=1)\n",
    "z = model.encode(x_test, data.edge_index)\n",
    "final_edge_index = model.decode_all(z)\n",
    "\n",
    "\n",
    "predicted_adj = to_dense_adj(final_edge_index).squeeze(0).to('cpu')\n",
    "(adj_matrix[senadores_no_presentes][:,n_P1+n_P2:]==predicted_adj[senadores_no_presentes][:,n_P1+n_P2:]).sum() / 48 / 230"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GLASE embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.9126, Val: 0.7181, Test: 0.6946\n",
      "Epoch: 002, Loss: 0.6863, Val: 0.7589, Test: 0.7235\n",
      "Epoch: 003, Loss: 0.6503, Val: 0.7725, Test: 0.7417\n",
      "Epoch: 004, Loss: 0.6319, Val: 0.8122, Test: 0.7988\n",
      "Epoch: 005, Loss: 0.6119, Val: 0.8434, Test: 0.8359\n",
      "Epoch: 006, Loss: 0.5813, Val: 0.8629, Test: 0.8494\n",
      "Epoch: 007, Loss: 0.5719, Val: 0.8715, Test: 0.8499\n",
      "Epoch: 008, Loss: 0.5638, Val: 0.8738, Test: 0.8505\n",
      "Epoch: 009, Loss: 0.5510, Val: 0.8760, Test: 0.8530\n",
      "Epoch: 010, Loss: 0.5423, Val: 0.8796, Test: 0.8566\n",
      "Epoch: 011, Loss: 0.5639, Val: 0.8812, Test: 0.8583\n",
      "Epoch: 012, Loss: 0.5478, Val: 0.8813, Test: 0.8579\n",
      "Epoch: 013, Loss: 0.5420, Val: 0.8809, Test: 0.8573\n",
      "Epoch: 014, Loss: 0.5383, Val: 0.8801, Test: 0.8570\n",
      "Epoch: 015, Loss: 0.5342, Val: 0.8792, Test: 0.8572\n",
      "Epoch: 016, Loss: 0.5366, Val: 0.8786, Test: 0.8566\n",
      "Epoch: 017, Loss: 0.5367, Val: 0.8778, Test: 0.8558\n",
      "Epoch: 018, Loss: 0.5422, Val: 0.8770, Test: 0.8547\n",
      "Epoch: 019, Loss: 0.5379, Val: 0.8755, Test: 0.8547\n",
      "Epoch: 020, Loss: 0.5311, Val: 0.8767, Test: 0.8555\n",
      "Epoch: 021, Loss: 0.5361, Val: 0.8776, Test: 0.8560\n",
      "Epoch: 022, Loss: 0.5343, Val: 0.8776, Test: 0.8566\n",
      "Epoch: 023, Loss: 0.5402, Val: 0.8771, Test: 0.8570\n",
      "Epoch: 024, Loss: 0.5436, Val: 0.8767, Test: 0.8577\n",
      "Epoch: 025, Loss: 0.5359, Val: 0.8769, Test: 0.8572\n",
      "Epoch: 026, Loss: 0.5385, Val: 0.8770, Test: 0.8568\n",
      "Epoch: 027, Loss: 0.5224, Val: 0.8774, Test: 0.8567\n",
      "Epoch: 028, Loss: 0.5303, Val: 0.8781, Test: 0.8564\n",
      "Epoch: 029, Loss: 0.5319, Val: 0.8783, Test: 0.8566\n",
      "Epoch: 030, Loss: 0.5310, Val: 0.8783, Test: 0.8566\n",
      "Epoch: 031, Loss: 0.5301, Val: 0.8786, Test: 0.8565\n",
      "Epoch: 032, Loss: 0.5348, Val: 0.8790, Test: 0.8569\n",
      "Epoch: 033, Loss: 0.5407, Val: 0.8791, Test: 0.8571\n",
      "Epoch: 034, Loss: 0.5422, Val: 0.8788, Test: 0.8570\n",
      "Epoch: 035, Loss: 0.5349, Val: 0.8781, Test: 0.8571\n",
      "Epoch: 036, Loss: 0.5328, Val: 0.8777, Test: 0.8586\n",
      "Epoch: 037, Loss: 0.5291, Val: 0.8771, Test: 0.8589\n",
      "Epoch: 038, Loss: 0.5271, Val: 0.8777, Test: 0.8588\n",
      "Epoch: 039, Loss: 0.5292, Val: 0.8783, Test: 0.8572\n",
      "Epoch: 040, Loss: 0.5337, Val: 0.8790, Test: 0.8571\n",
      "Epoch: 041, Loss: 0.5316, Val: 0.8787, Test: 0.8567\n",
      "Epoch: 042, Loss: 0.5237, Val: 0.8776, Test: 0.8575\n",
      "Epoch: 043, Loss: 0.5331, Val: 0.8775, Test: 0.8578\n",
      "Epoch: 044, Loss: 0.5267, Val: 0.8777, Test: 0.8573\n",
      "Epoch: 045, Loss: 0.5383, Val: 0.8783, Test: 0.8565\n",
      "Epoch: 046, Loss: 0.5353, Val: 0.8789, Test: 0.8568\n",
      "Epoch: 047, Loss: 0.5307, Val: 0.8789, Test: 0.8567\n",
      "Epoch: 048, Loss: 0.5340, Val: 0.8789, Test: 0.8567\n",
      "Epoch: 049, Loss: 0.5362, Val: 0.8784, Test: 0.8568\n",
      "Epoch: 050, Loss: 0.5325, Val: 0.8787, Test: 0.8568\n",
      "Epoch: 051, Loss: 0.5310, Val: 0.8786, Test: 0.8569\n",
      "Epoch: 052, Loss: 0.5291, Val: 0.8783, Test: 0.8569\n",
      "Epoch: 053, Loss: 0.5382, Val: 0.8782, Test: 0.8570\n",
      "Epoch: 054, Loss: 0.5282, Val: 0.8784, Test: 0.8571\n",
      "Epoch: 055, Loss: 0.5343, Val: 0.8785, Test: 0.8573\n",
      "Epoch: 056, Loss: 0.5314, Val: 0.8784, Test: 0.8575\n",
      "Epoch: 057, Loss: 0.5340, Val: 0.8790, Test: 0.8571\n",
      "Epoch: 058, Loss: 0.5308, Val: 0.8791, Test: 0.8571\n",
      "Epoch: 059, Loss: 0.5273, Val: 0.8787, Test: 0.8570\n",
      "Epoch: 060, Loss: 0.5319, Val: 0.8781, Test: 0.8577\n",
      "Epoch: 061, Loss: 0.5373, Val: 0.8781, Test: 0.8578\n",
      "Epoch: 062, Loss: 0.5360, Val: 0.8786, Test: 0.8572\n",
      "Epoch: 063, Loss: 0.5332, Val: 0.8791, Test: 0.8571\n",
      "Epoch: 064, Loss: 0.5379, Val: 0.8783, Test: 0.8580\n",
      "Epoch: 065, Loss: 0.5338, Val: 0.8781, Test: 0.8587\n",
      "Epoch: 066, Loss: 0.5273, Val: 0.8779, Test: 0.8583\n",
      "Epoch: 067, Loss: 0.5360, Val: 0.8785, Test: 0.8577\n",
      "Epoch: 068, Loss: 0.5270, Val: 0.8785, Test: 0.8577\n",
      "Epoch: 069, Loss: 0.5221, Val: 0.8789, Test: 0.8585\n",
      "Epoch: 070, Loss: 0.5288, Val: 0.8787, Test: 0.8584\n",
      "Epoch: 071, Loss: 0.5269, Val: 0.8791, Test: 0.8580\n",
      "Epoch: 072, Loss: 0.5341, Val: 0.8796, Test: 0.8573\n",
      "Epoch: 073, Loss: 0.5324, Val: 0.8792, Test: 0.8572\n",
      "Epoch: 074, Loss: 0.5296, Val: 0.8787, Test: 0.8578\n",
      "Epoch: 075, Loss: 0.5302, Val: 0.8785, Test: 0.8592\n",
      "Epoch: 076, Loss: 0.5286, Val: 0.8787, Test: 0.8595\n",
      "Epoch: 077, Loss: 0.5226, Val: 0.8785, Test: 0.8585\n",
      "Epoch: 078, Loss: 0.5316, Val: 0.8796, Test: 0.8578\n",
      "Epoch: 079, Loss: 0.5327, Val: 0.8803, Test: 0.8576\n",
      "Epoch: 080, Loss: 0.5304, Val: 0.8803, Test: 0.8580\n",
      "Epoch: 081, Loss: 0.5317, Val: 0.8795, Test: 0.8584\n",
      "Epoch: 082, Loss: 0.5325, Val: 0.8794, Test: 0.8593\n",
      "Epoch: 083, Loss: 0.5287, Val: 0.8788, Test: 0.8592\n",
      "Epoch: 084, Loss: 0.5304, Val: 0.8784, Test: 0.8587\n",
      "Epoch: 085, Loss: 0.5295, Val: 0.8782, Test: 0.8593\n",
      "Epoch: 086, Loss: 0.5305, Val: 0.8787, Test: 0.8597\n",
      "Epoch: 087, Loss: 0.5366, Val: 0.8788, Test: 0.8600\n",
      "Epoch: 088, Loss: 0.5347, Val: 0.8793, Test: 0.8600\n",
      "Epoch: 089, Loss: 0.5336, Val: 0.8802, Test: 0.8604\n",
      "Epoch: 090, Loss: 0.5269, Val: 0.8808, Test: 0.8598\n",
      "Epoch: 091, Loss: 0.5237, Val: 0.8807, Test: 0.8597\n",
      "Epoch: 092, Loss: 0.5339, Val: 0.8800, Test: 0.8604\n",
      "Epoch: 093, Loss: 0.5296, Val: 0.8791, Test: 0.8608\n",
      "Epoch: 094, Loss: 0.5235, Val: 0.8788, Test: 0.8606\n",
      "Epoch: 095, Loss: 0.5293, Val: 0.8791, Test: 0.8601\n",
      "Epoch: 096, Loss: 0.5308, Val: 0.8793, Test: 0.8595\n",
      "Epoch: 097, Loss: 0.5215, Val: 0.8808, Test: 0.8598\n",
      "Epoch: 098, Loss: 0.5259, Val: 0.8820, Test: 0.8608\n",
      "Epoch: 099, Loss: 0.5331, Val: 0.8821, Test: 0.8615\n",
      "Epoch: 100, Loss: 0.5294, Val: 0.8812, Test: 0.8612\n",
      "Final Test: 0.8615\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.nn import GCNConv\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from torch_geometric.utils import negative_sampling\n",
    "\n",
    "\n",
    "model = Net(9, 128, 64).to(device)\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    x_train = torch.concatenate((train_data.x, train_data.x_glase), axis=1)\n",
    "    z = model.encode(x_train, train_data.edge_index)\n",
    "\n",
    "    # We perform a new round of negative sampling for every training epoch:\n",
    "    neg_edge_index = negative_sampling(\n",
    "        edge_index=train_data.edge_index, num_nodes=train_data.num_nodes,\n",
    "        num_neg_samples=train_data.edge_label_index.size(1), method='sparse')\n",
    "\n",
    "    edge_label_index = torch.cat(\n",
    "        [train_data.edge_label_index, neg_edge_index],\n",
    "        dim=-1,\n",
    "    )\n",
    "    edge_label = torch.cat([\n",
    "        train_data.edge_label,\n",
    "        train_data.edge_label.new_zeros(neg_edge_index.size(1))\n",
    "    ], dim=0)\n",
    "\n",
    "    out = model.decode(z, edge_label_index).view(-1)\n",
    "    loss = criterion(out, edge_label)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(data):\n",
    "    model.eval()\n",
    "    x_test = torch.concatenate((data.x, data.x_glase), axis=1)\n",
    "    z = model.encode(x_test, data.edge_index)\n",
    "    out = model.decode(z, data.edge_label_index).view(-1).sigmoid()\n",
    "    return roc_auc_score(data.edge_label.cpu().numpy(), out.cpu().numpy())\n",
    "\n",
    "\n",
    "best_val_auc = final_test_auc = 0\n",
    "for epoch in range(1, 101):\n",
    "    loss = train()\n",
    "    val_auc = test(val_data)\n",
    "    test_auc = test(test_data)\n",
    "    if val_auc > best_val_auc:\n",
    "        best_val_auc = val_auc\n",
    "        final_test_auc = test_auc\n",
    "    print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Val: {val_auc:.4f}, '\n",
    "          f'Test: {test_auc:.4f}')\n",
    "\n",
    "print(f'Final Test: {final_test_auc:.4f}')\n",
    "\n",
    "x_test = torch.concatenate((test_data.x, test_data.x_glase), axis=1)\n",
    "z = model.encode(x_test, test_data.edge_index)\n",
    "final_edge_index = model.decode_all(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8653)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Predict on entire masked graph\n",
    "x_test = torch.concatenate((data.x, data.x_glase), axis=1)\n",
    "z = model.encode(x_test, data.edge_index)\n",
    "final_edge_index = model.decode_all(z)\n",
    "\n",
    "\n",
    "predicted_adj = to_dense_adj(final_edge_index).squeeze(0).to('cpu')\n",
    "(adj_matrix[senadores_no_presentes][:,n_P1+n_P2:]==predicted_adj[senadores_no_presentes][:,n_P1+n_P2:]).sum() / 48 / 230"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8823, 0.9150, 0.3829, 0.9593, 0.3904],\n",
       "        [0.6009, 0.2566, 0.7936, 0.9408, 0.1332],\n",
       "        [0.9346, 0.5936, 0.8694, 0.5677, 0.7411],\n",
       "        ...,\n",
       "        [0.1418, 0.3650, 0.0908, 0.6902, 0.8538],\n",
       "        [0.5396, 0.1421, 0.1213, 0.3054, 0.6454],\n",
       "        [0.5122, 0.5909, 0.9712, 0.7322, 0.6075]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "random_features=torch.rand([410, 5])\n",
    "random_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Split Train, Val, Test\n",
    "from torch_geometric.data import Data\n",
    "import torch_geometric.transforms as T\n",
    "\n",
    "device = 'cuda'\n",
    "\n",
    "masked_edge_index = masked_adj.nonzero().t().contiguous()\n",
    "\n",
    "data = Data(x=random_features.float(), x_ase=x_ase, x_glase=x_glase, edge_index=masked_edge_index)\n",
    "\n",
    "transform = T.Compose([\n",
    "    # T.NormalizeFeatures(),\n",
    "    T.ToDevice(device),\n",
    "    T.RandomLinkSplit(num_val=0.05, num_test=0.1, is_undirected=True,\n",
    "                      add_negative_train_samples=False),\n",
    "])\n",
    "\n",
    "\n",
    "train_data, val_data, test_data = transform(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GCN Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.6953, Val: 0.7959, Test: 0.7682\n",
      "Epoch: 002, Loss: 0.6734, Val: 0.7978, Test: 0.7710\n",
      "Epoch: 003, Loss: 0.6809, Val: 0.7980, Test: 0.7714\n",
      "Epoch: 004, Loss: 0.6712, Val: 0.7983, Test: 0.7721\n",
      "Epoch: 005, Loss: 0.6708, Val: 0.7985, Test: 0.7726\n",
      "Epoch: 006, Loss: 0.6709, Val: 0.7992, Test: 0.7731\n",
      "Epoch: 007, Loss: 0.6690, Val: 0.7995, Test: 0.7734\n",
      "Epoch: 008, Loss: 0.6676, Val: 0.7998, Test: 0.7736\n",
      "Epoch: 009, Loss: 0.6663, Val: 0.8001, Test: 0.7738\n",
      "Epoch: 010, Loss: 0.6657, Val: 0.8005, Test: 0.7740\n",
      "Epoch: 011, Loss: 0.6627, Val: 0.8008, Test: 0.7741\n",
      "Epoch: 012, Loss: 0.6600, Val: 0.8007, Test: 0.7739\n",
      "Epoch: 013, Loss: 0.6568, Val: 0.8008, Test: 0.7739\n",
      "Epoch: 014, Loss: 0.6553, Val: 0.8009, Test: 0.7737\n",
      "Epoch: 015, Loss: 0.6501, Val: 0.8011, Test: 0.7737\n",
      "Epoch: 016, Loss: 0.6479, Val: 0.8006, Test: 0.7735\n",
      "Epoch: 017, Loss: 0.6471, Val: 0.7997, Test: 0.7727\n",
      "Epoch: 018, Loss: 0.6421, Val: 0.7988, Test: 0.7720\n",
      "Epoch: 019, Loss: 0.6374, Val: 0.7988, Test: 0.7714\n",
      "Epoch: 020, Loss: 0.6370, Val: 0.7987, Test: 0.7715\n",
      "Epoch: 021, Loss: 0.6375, Val: 0.7986, Test: 0.7712\n",
      "Epoch: 022, Loss: 0.6342, Val: 0.7981, Test: 0.7704\n",
      "Epoch: 023, Loss: 0.6311, Val: 0.7963, Test: 0.7692\n",
      "Epoch: 024, Loss: 0.6306, Val: 0.7953, Test: 0.7684\n",
      "Epoch: 025, Loss: 0.6262, Val: 0.7953, Test: 0.7685\n",
      "Epoch: 026, Loss: 0.6237, Val: 0.7953, Test: 0.7684\n",
      "Epoch: 027, Loss: 0.6262, Val: 0.7939, Test: 0.7666\n",
      "Epoch: 028, Loss: 0.6253, Val: 0.7924, Test: 0.7629\n",
      "Epoch: 029, Loss: 0.6235, Val: 0.7926, Test: 0.7615\n",
      "Epoch: 030, Loss: 0.6179, Val: 0.7927, Test: 0.7638\n",
      "Epoch: 031, Loss: 0.6166, Val: 0.7929, Test: 0.7631\n",
      "Epoch: 032, Loss: 0.6203, Val: 0.7908, Test: 0.7554\n",
      "Epoch: 033, Loss: 0.6178, Val: 0.7863, Test: 0.7506\n",
      "Epoch: 034, Loss: 0.6123, Val: 0.7907, Test: 0.7544\n",
      "Epoch: 035, Loss: 0.6083, Val: 0.7927, Test: 0.7575\n",
      "Epoch: 036, Loss: 0.6128, Val: 0.7874, Test: 0.7519\n",
      "Epoch: 037, Loss: 0.6074, Val: 0.7800, Test: 0.7449\n",
      "Epoch: 038, Loss: 0.6107, Val: 0.7798, Test: 0.7447\n",
      "Epoch: 039, Loss: 0.6095, Val: 0.7842, Test: 0.7495\n",
      "Epoch: 040, Loss: 0.6099, Val: 0.7841, Test: 0.7494\n",
      "Epoch: 041, Loss: 0.6041, Val: 0.7787, Test: 0.7440\n",
      "Epoch: 042, Loss: 0.6064, Val: 0.7743, Test: 0.7397\n",
      "Epoch: 043, Loss: 0.6043, Val: 0.7760, Test: 0.7417\n",
      "Epoch: 044, Loss: 0.6014, Val: 0.7788, Test: 0.7451\n",
      "Epoch: 045, Loss: 0.6057, Val: 0.7758, Test: 0.7414\n",
      "Epoch: 046, Loss: 0.5957, Val: 0.7730, Test: 0.7384\n",
      "Epoch: 047, Loss: 0.5983, Val: 0.7725, Test: 0.7379\n",
      "Epoch: 048, Loss: 0.6023, Val: 0.7728, Test: 0.7382\n",
      "Epoch: 049, Loss: 0.6038, Val: 0.7708, Test: 0.7361\n",
      "Epoch: 050, Loss: 0.6002, Val: 0.7705, Test: 0.7358\n",
      "Epoch: 051, Loss: 0.6045, Val: 0.7696, Test: 0.7347\n",
      "Epoch: 052, Loss: 0.5975, Val: 0.7701, Test: 0.7353\n",
      "Epoch: 053, Loss: 0.6024, Val: 0.7682, Test: 0.7333\n",
      "Epoch: 054, Loss: 0.5988, Val: 0.7673, Test: 0.7327\n",
      "Epoch: 055, Loss: 0.5958, Val: 0.7695, Test: 0.7345\n",
      "Epoch: 056, Loss: 0.5989, Val: 0.7677, Test: 0.7331\n",
      "Epoch: 057, Loss: 0.5953, Val: 0.7655, Test: 0.7316\n",
      "Epoch: 058, Loss: 0.6014, Val: 0.7649, Test: 0.7314\n",
      "Epoch: 059, Loss: 0.5991, Val: 0.7661, Test: 0.7320\n",
      "Epoch: 060, Loss: 0.5940, Val: 0.7664, Test: 0.7324\n",
      "Epoch: 061, Loss: 0.5960, Val: 0.7644, Test: 0.7310\n",
      "Epoch: 062, Loss: 0.5956, Val: 0.7638, Test: 0.7301\n",
      "Epoch: 063, Loss: 0.5956, Val: 0.7651, Test: 0.7315\n",
      "Epoch: 064, Loss: 0.6018, Val: 0.7630, Test: 0.7298\n",
      "Epoch: 065, Loss: 0.5973, Val: 0.7627, Test: 0.7294\n",
      "Epoch: 066, Loss: 0.6020, Val: 0.7640, Test: 0.7304\n",
      "Epoch: 067, Loss: 0.5935, Val: 0.7646, Test: 0.7309\n",
      "Epoch: 068, Loss: 0.6104, Val: 0.7578, Test: 0.7260\n",
      "Epoch: 069, Loss: 0.5999, Val: 0.7627, Test: 0.7294\n",
      "Epoch: 070, Loss: 0.5955, Val: 0.7678, Test: 0.7336\n",
      "Epoch: 071, Loss: 0.6007, Val: 0.7606, Test: 0.7281\n",
      "Epoch: 072, Loss: 0.5925, Val: 0.7594, Test: 0.7274\n",
      "Epoch: 073, Loss: 0.5996, Val: 0.7647, Test: 0.7310\n",
      "Epoch: 074, Loss: 0.5991, Val: 0.7644, Test: 0.7307\n",
      "Epoch: 075, Loss: 0.5986, Val: 0.7598, Test: 0.7276\n",
      "Epoch: 076, Loss: 0.5935, Val: 0.7623, Test: 0.7292\n",
      "Epoch: 077, Loss: 0.5904, Val: 0.7657, Test: 0.7320\n",
      "Epoch: 078, Loss: 0.6083, Val: 0.7598, Test: 0.7276\n",
      "Epoch: 079, Loss: 0.5976, Val: 0.7580, Test: 0.7262\n",
      "Epoch: 080, Loss: 0.5981, Val: 0.7636, Test: 0.7301\n",
      "Epoch: 081, Loss: 0.5964, Val: 0.7656, Test: 0.7319\n",
      "Epoch: 082, Loss: 0.6050, Val: 0.7596, Test: 0.7273\n",
      "Epoch: 083, Loss: 0.6002, Val: 0.7580, Test: 0.7260\n",
      "Epoch: 084, Loss: 0.6015, Val: 0.7639, Test: 0.7303\n",
      "Epoch: 085, Loss: 0.5980, Val: 0.7652, Test: 0.7315\n",
      "Epoch: 086, Loss: 0.6028, Val: 0.7605, Test: 0.7278\n",
      "Epoch: 087, Loss: 0.5986, Val: 0.7591, Test: 0.7269\n",
      "Epoch: 088, Loss: 0.5937, Val: 0.7652, Test: 0.7314\n",
      "Epoch: 089, Loss: 0.5964, Val: 0.7660, Test: 0.7321\n",
      "Epoch: 090, Loss: 0.5982, Val: 0.7602, Test: 0.7276\n",
      "Epoch: 091, Loss: 0.6007, Val: 0.7583, Test: 0.7262\n",
      "Epoch: 092, Loss: 0.5993, Val: 0.7642, Test: 0.7306\n",
      "Epoch: 093, Loss: 0.5927, Val: 0.7682, Test: 0.7339\n",
      "Epoch: 094, Loss: 0.6061, Val: 0.7608, Test: 0.7279\n",
      "Epoch: 095, Loss: 0.6017, Val: 0.7562, Test: 0.7244\n",
      "Epoch: 096, Loss: 0.6025, Val: 0.7625, Test: 0.7291\n",
      "Epoch: 097, Loss: 0.5933, Val: 0.7691, Test: 0.7351\n",
      "Epoch: 098, Loss: 0.6023, Val: 0.7647, Test: 0.7309\n",
      "Epoch: 099, Loss: 0.6044, Val: 0.7553, Test: 0.7235\n",
      "Epoch: 100, Loss: 0.6026, Val: 0.7583, Test: 0.7261\n",
      "Final Test: 0.7737\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.nn import GCNConv\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from torch_geometric.utils import negative_sampling\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, out_channels)\n",
    "\n",
    "    def encode(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        return self.conv2(x, edge_index)\n",
    "\n",
    "    def decode(self, z, edge_label_index):\n",
    "        return (z[edge_label_index[0]] * z[edge_label_index[1]]).sum(dim=-1)\n",
    "\n",
    "    def decode_all(self, z):\n",
    "        prob_adj = z @ z.t()\n",
    "        return (prob_adj > 0).nonzero(as_tuple=False).t()\n",
    "\n",
    "\n",
    "model = Net(5, 128, 64).to(device)\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    z = model.encode(train_data.x, train_data.edge_index)\n",
    "\n",
    "    # We perform a new round of negative sampling for every training epoch:\n",
    "    neg_edge_index = negative_sampling(\n",
    "        edge_index=train_data.edge_index, num_nodes=train_data.num_nodes,\n",
    "        num_neg_samples=train_data.edge_label_index.size(1), method='sparse')\n",
    "\n",
    "    edge_label_index = torch.cat(\n",
    "        [train_data.edge_label_index, neg_edge_index],\n",
    "        dim=-1,\n",
    "    )\n",
    "    edge_label = torch.cat([\n",
    "        train_data.edge_label,\n",
    "        train_data.edge_label.new_zeros(neg_edge_index.size(1))\n",
    "    ], dim=0)\n",
    "\n",
    "    out = model.decode(z, edge_label_index).view(-1)\n",
    "    loss = criterion(out, edge_label)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(data):\n",
    "    model.eval()\n",
    "    z = model.encode(data.x, data.edge_index)\n",
    "    out = model.decode(z, data.edge_label_index).view(-1).sigmoid()\n",
    "    return roc_auc_score(data.edge_label.cpu().numpy(), out.cpu().numpy())\n",
    "\n",
    "\n",
    "best_val_auc = final_test_auc = 0\n",
    "for epoch in range(1, 101):\n",
    "    loss = train()\n",
    "    val_auc = test(val_data)\n",
    "    test_auc = test(test_data)\n",
    "    if val_auc > best_val_auc:\n",
    "        best_val_auc = val_auc\n",
    "        final_test_auc = test_auc\n",
    "    print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Val: {val_auc:.4f}, '\n",
    "          f'Test: {test_auc:.4f}')\n",
    "\n",
    "print(f'Final Test: {final_test_auc:.4f}')\n",
    "\n",
    "z = model.encode(test_data.x, test_data.edge_index)\n",
    "final_edge_index = model.decode_all(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5478)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Predict on entire masked graph\n",
    "\n",
    "z = model.encode(data.x, data.edge_index)\n",
    "final_edge_index = model.decode_all(z)\n",
    "\n",
    "\n",
    "predicted_adj = to_dense_adj(final_edge_index).squeeze(0).to('cpu')\n",
    "(adj_matrix[senadores_no_presentes][:,n_P1+n_P2:]==predicted_adj[senadores_no_presentes][:,n_P1+n_P2:]).sum() / (n_P1_np+n_P2_np) / 230\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ASE Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.7001, Val: 0.7913, Test: 0.7788\n",
      "Epoch: 002, Loss: 0.6708, Val: 0.8226, Test: 0.8024\n",
      "Epoch: 003, Loss: 0.6873, Val: 0.8418, Test: 0.8290\n",
      "Epoch: 004, Loss: 0.6504, Val: 0.8587, Test: 0.8550\n",
      "Epoch: 005, Loss: 0.6426, Val: 0.8519, Test: 0.8576\n",
      "Epoch: 006, Loss: 0.6330, Val: 0.8455, Test: 0.8506\n",
      "Epoch: 007, Loss: 0.6160, Val: 0.8431, Test: 0.8489\n",
      "Epoch: 008, Loss: 0.5968, Val: 0.8409, Test: 0.8468\n",
      "Epoch: 009, Loss: 0.5832, Val: 0.8383, Test: 0.8420\n",
      "Epoch: 010, Loss: 0.5665, Val: 0.8349, Test: 0.8386\n",
      "Epoch: 011, Loss: 0.5566, Val: 0.8340, Test: 0.8353\n",
      "Epoch: 012, Loss: 0.5475, Val: 0.8326, Test: 0.8351\n",
      "Epoch: 013, Loss: 0.5462, Val: 0.8328, Test: 0.8335\n",
      "Epoch: 014, Loss: 0.5446, Val: 0.8326, Test: 0.8332\n",
      "Epoch: 015, Loss: 0.5444, Val: 0.8310, Test: 0.8345\n",
      "Epoch: 016, Loss: 0.5416, Val: 0.8332, Test: 0.8313\n",
      "Epoch: 017, Loss: 0.5371, Val: 0.8328, Test: 0.8299\n",
      "Epoch: 018, Loss: 0.5487, Val: 0.8335, Test: 0.8331\n",
      "Epoch: 019, Loss: 0.5439, Val: 0.8316, Test: 0.8365\n",
      "Epoch: 020, Loss: 0.5414, Val: 0.8328, Test: 0.8361\n",
      "Epoch: 021, Loss: 0.5476, Val: 0.8333, Test: 0.8346\n",
      "Epoch: 022, Loss: 0.5413, Val: 0.8331, Test: 0.8349\n",
      "Epoch: 023, Loss: 0.5385, Val: 0.8330, Test: 0.8368\n",
      "Epoch: 024, Loss: 0.5418, Val: 0.8300, Test: 0.8372\n",
      "Epoch: 025, Loss: 0.5388, Val: 0.8319, Test: 0.8376\n",
      "Epoch: 026, Loss: 0.5418, Val: 0.8330, Test: 0.8362\n",
      "Epoch: 027, Loss: 0.5348, Val: 0.8330, Test: 0.8354\n",
      "Epoch: 028, Loss: 0.5354, Val: 0.8328, Test: 0.8367\n",
      "Epoch: 029, Loss: 0.5349, Val: 0.8313, Test: 0.8372\n",
      "Epoch: 030, Loss: 0.5346, Val: 0.8324, Test: 0.8368\n",
      "Epoch: 031, Loss: 0.5321, Val: 0.8330, Test: 0.8346\n",
      "Epoch: 032, Loss: 0.5338, Val: 0.8333, Test: 0.8341\n",
      "Epoch: 033, Loss: 0.5372, Val: 0.8327, Test: 0.8363\n",
      "Epoch: 034, Loss: 0.5329, Val: 0.8307, Test: 0.8373\n",
      "Epoch: 035, Loss: 0.5391, Val: 0.8323, Test: 0.8363\n",
      "Epoch: 036, Loss: 0.5292, Val: 0.8330, Test: 0.8347\n",
      "Epoch: 037, Loss: 0.5351, Val: 0.8328, Test: 0.8343\n",
      "Epoch: 038, Loss: 0.5415, Val: 0.8320, Test: 0.8362\n",
      "Epoch: 039, Loss: 0.5344, Val: 0.8309, Test: 0.8370\n",
      "Epoch: 040, Loss: 0.5313, Val: 0.8327, Test: 0.8361\n",
      "Epoch: 041, Loss: 0.5311, Val: 0.8330, Test: 0.8356\n",
      "Epoch: 042, Loss: 0.5363, Val: 0.8331, Test: 0.8357\n",
      "Epoch: 043, Loss: 0.5322, Val: 0.8332, Test: 0.8369\n",
      "Epoch: 044, Loss: 0.5340, Val: 0.8329, Test: 0.8376\n",
      "Epoch: 045, Loss: 0.5336, Val: 0.8330, Test: 0.8376\n",
      "Epoch: 046, Loss: 0.5287, Val: 0.8336, Test: 0.8373\n",
      "Epoch: 047, Loss: 0.5279, Val: 0.8333, Test: 0.8370\n",
      "Epoch: 048, Loss: 0.5324, Val: 0.8334, Test: 0.8377\n",
      "Epoch: 049, Loss: 0.5363, Val: 0.8321, Test: 0.8377\n",
      "Epoch: 050, Loss: 0.5330, Val: 0.8318, Test: 0.8375\n",
      "Epoch: 051, Loss: 0.5312, Val: 0.8330, Test: 0.8373\n",
      "Epoch: 052, Loss: 0.5328, Val: 0.8337, Test: 0.8373\n",
      "Epoch: 053, Loss: 0.5263, Val: 0.8330, Test: 0.8377\n",
      "Epoch: 054, Loss: 0.5369, Val: 0.8323, Test: 0.8376\n",
      "Epoch: 055, Loss: 0.5311, Val: 0.8326, Test: 0.8380\n",
      "Epoch: 056, Loss: 0.5316, Val: 0.8338, Test: 0.8384\n",
      "Epoch: 057, Loss: 0.5289, Val: 0.8345, Test: 0.8385\n",
      "Epoch: 058, Loss: 0.5360, Val: 0.8338, Test: 0.8385\n",
      "Epoch: 059, Loss: 0.5250, Val: 0.8341, Test: 0.8385\n",
      "Epoch: 060, Loss: 0.5317, Val: 0.8343, Test: 0.8386\n",
      "Epoch: 061, Loss: 0.5321, Val: 0.8348, Test: 0.8390\n",
      "Epoch: 062, Loss: 0.5279, Val: 0.8354, Test: 0.8386\n",
      "Epoch: 063, Loss: 0.5248, Val: 0.8353, Test: 0.8391\n",
      "Epoch: 064, Loss: 0.5291, Val: 0.8345, Test: 0.8386\n",
      "Epoch: 065, Loss: 0.5190, Val: 0.8346, Test: 0.8386\n",
      "Epoch: 066, Loss: 0.5322, Val: 0.8348, Test: 0.8388\n",
      "Epoch: 067, Loss: 0.5267, Val: 0.8354, Test: 0.8388\n",
      "Epoch: 068, Loss: 0.5297, Val: 0.8342, Test: 0.8384\n",
      "Epoch: 069, Loss: 0.5221, Val: 0.8345, Test: 0.8390\n",
      "Epoch: 070, Loss: 0.5213, Val: 0.8360, Test: 0.8403\n",
      "Epoch: 071, Loss: 0.5219, Val: 0.8374, Test: 0.8414\n",
      "Epoch: 072, Loss: 0.5265, Val: 0.8376, Test: 0.8415\n",
      "Epoch: 073, Loss: 0.5242, Val: 0.8353, Test: 0.8394\n",
      "Epoch: 074, Loss: 0.5266, Val: 0.8336, Test: 0.8380\n",
      "Epoch: 075, Loss: 0.5204, Val: 0.8339, Test: 0.8377\n",
      "Epoch: 076, Loss: 0.5273, Val: 0.8346, Test: 0.8381\n",
      "Epoch: 077, Loss: 0.5213, Val: 0.8371, Test: 0.8405\n",
      "Epoch: 078, Loss: 0.5222, Val: 0.8377, Test: 0.8413\n",
      "Epoch: 079, Loss: 0.5239, Val: 0.8367, Test: 0.8406\n",
      "Epoch: 080, Loss: 0.5190, Val: 0.8347, Test: 0.8387\n",
      "Epoch: 081, Loss: 0.5170, Val: 0.8346, Test: 0.8378\n",
      "Epoch: 082, Loss: 0.5184, Val: 0.8355, Test: 0.8388\n",
      "Epoch: 083, Loss: 0.5155, Val: 0.8363, Test: 0.8397\n",
      "Epoch: 084, Loss: 0.5213, Val: 0.8363, Test: 0.8404\n",
      "Epoch: 085, Loss: 0.5200, Val: 0.8355, Test: 0.8394\n",
      "Epoch: 086, Loss: 0.5134, Val: 0.8347, Test: 0.8380\n",
      "Epoch: 087, Loss: 0.5170, Val: 0.8361, Test: 0.8390\n",
      "Epoch: 088, Loss: 0.5191, Val: 0.8364, Test: 0.8395\n",
      "Epoch: 089, Loss: 0.5145, Val: 0.8367, Test: 0.8398\n",
      "Epoch: 090, Loss: 0.5214, Val: 0.8364, Test: 0.8392\n",
      "Epoch: 091, Loss: 0.5250, Val: 0.8348, Test: 0.8368\n",
      "Epoch: 092, Loss: 0.5333, Val: 0.8326, Test: 0.8351\n",
      "Epoch: 093, Loss: 0.5221, Val: 0.8347, Test: 0.8371\n",
      "Epoch: 094, Loss: 0.5198, Val: 0.8363, Test: 0.8391\n",
      "Epoch: 095, Loss: 0.5162, Val: 0.8368, Test: 0.8400\n",
      "Epoch: 096, Loss: 0.5078, Val: 0.8337, Test: 0.8371\n",
      "Epoch: 097, Loss: 0.5196, Val: 0.8305, Test: 0.8330\n",
      "Epoch: 098, Loss: 0.5204, Val: 0.8301, Test: 0.8316\n",
      "Epoch: 099, Loss: 0.5199, Val: 0.8323, Test: 0.8348\n",
      "Epoch: 100, Loss: 0.5197, Val: 0.8362, Test: 0.8382\n",
      "Final Test: 0.8550\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.nn import GCNConv\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from torch_geometric.utils import negative_sampling\n",
    "\n",
    "\n",
    "model = Net(9, 128, 64).to(device)\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    x_train = torch.concatenate((train_data.x, train_data.x_ase), axis=1)\n",
    "    z = model.encode(x_train, train_data.edge_index)\n",
    "\n",
    "    # We perform a new round of negative sampling for every training epoch:\n",
    "    neg_edge_index = negative_sampling(\n",
    "        edge_index=train_data.edge_index, num_nodes=train_data.num_nodes,\n",
    "        num_neg_samples=train_data.edge_label_index.size(1), method='sparse')\n",
    "\n",
    "    edge_label_index = torch.cat(\n",
    "        [train_data.edge_label_index, neg_edge_index],\n",
    "        dim=-1,\n",
    "    )\n",
    "    edge_label = torch.cat([\n",
    "        train_data.edge_label,\n",
    "        train_data.edge_label.new_zeros(neg_edge_index.size(1))\n",
    "    ], dim=0)\n",
    "\n",
    "    out = model.decode(z, edge_label_index).view(-1)\n",
    "    loss = criterion(out, edge_label)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(data):\n",
    "    model.eval()\n",
    "    x_test = torch.concatenate((data.x, data.x_ase), axis=1)\n",
    "    z = model.encode(x_test, data.edge_index)\n",
    "    out = model.decode(z, data.edge_label_index).view(-1).sigmoid()\n",
    "    return roc_auc_score(data.edge_label.cpu().numpy(), out.cpu().numpy())\n",
    "\n",
    "\n",
    "best_val_auc = final_test_auc = 0\n",
    "for epoch in range(1, 101):\n",
    "    loss = train()\n",
    "    val_auc = test(val_data)\n",
    "    test_auc = test(test_data)\n",
    "    if val_auc > best_val_auc:\n",
    "        best_val_auc = val_auc\n",
    "        final_test_auc = test_auc\n",
    "    print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Val: {val_auc:.4f}, '\n",
    "          f'Test: {test_auc:.4f}')\n",
    "\n",
    "print(f'Final Test: {final_test_auc:.4f}')\n",
    "\n",
    "x_test = torch.concatenate((test_data.x, test_data.x_ase), axis=1)\n",
    "z = model.encode(x_test, test_data.edge_index)\n",
    "final_edge_index = model.decode_all(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8468)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Predict on entire masked graph\n",
    "x_test = torch.concatenate((data.x, data.x_ase), axis=1)\n",
    "z = model.encode(x_test, data.edge_index)\n",
    "final_edge_index = model.decode_all(z)\n",
    "\n",
    "\n",
    "predicted_adj = to_dense_adj(final_edge_index).squeeze(0).to('cpu')\n",
    "(adj_matrix[senadores_no_presentes][:,n_P1+n_P2:]==predicted_adj[senadores_no_presentes][:,n_P1+n_P2:]).sum() / (n_P1_np+n_P2_np) / 230"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GLASE Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.9686, Val: 0.6309, Test: 0.6366\n",
      "Epoch: 002, Loss: 0.7129, Val: 0.7318, Test: 0.7346\n",
      "Epoch: 003, Loss: 0.6964, Val: 0.7683, Test: 0.7674\n",
      "Epoch: 004, Loss: 0.6883, Val: 0.7797, Test: 0.7852\n",
      "Epoch: 005, Loss: 0.6685, Val: 0.7797, Test: 0.7873\n",
      "Epoch: 006, Loss: 0.6609, Val: 0.7843, Test: 0.7932\n",
      "Epoch: 007, Loss: 0.6556, Val: 0.7904, Test: 0.8046\n",
      "Epoch: 008, Loss: 0.6520, Val: 0.7887, Test: 0.8063\n",
      "Epoch: 009, Loss: 0.6418, Val: 0.7884, Test: 0.8054\n",
      "Epoch: 010, Loss: 0.6320, Val: 0.7891, Test: 0.8052\n",
      "Epoch: 011, Loss: 0.6280, Val: 0.7849, Test: 0.8025\n",
      "Epoch: 012, Loss: 0.6162, Val: 0.7778, Test: 0.7982\n",
      "Epoch: 013, Loss: 0.6132, Val: 0.7738, Test: 0.7937\n",
      "Epoch: 014, Loss: 0.5996, Val: 0.7722, Test: 0.7913\n",
      "Epoch: 015, Loss: 0.5857, Val: 0.7746, Test: 0.7917\n",
      "Epoch: 016, Loss: 0.5802, Val: 0.7824, Test: 0.7988\n",
      "Epoch: 017, Loss: 0.5668, Val: 0.7929, Test: 0.8070\n",
      "Epoch: 018, Loss: 0.5702, Val: 0.8016, Test: 0.8142\n",
      "Epoch: 019, Loss: 0.5655, Val: 0.8121, Test: 0.8240\n",
      "Epoch: 020, Loss: 0.5566, Val: 0.8203, Test: 0.8306\n",
      "Epoch: 021, Loss: 0.5476, Val: 0.8250, Test: 0.8333\n",
      "Epoch: 022, Loss: 0.5496, Val: 0.8275, Test: 0.8348\n",
      "Epoch: 023, Loss: 0.5388, Val: 0.8254, Test: 0.8345\n",
      "Epoch: 024, Loss: 0.5391, Val: 0.8293, Test: 0.8342\n",
      "Epoch: 025, Loss: 0.5371, Val: 0.8304, Test: 0.8323\n",
      "Epoch: 026, Loss: 0.5401, Val: 0.8309, Test: 0.8340\n",
      "Epoch: 027, Loss: 0.5426, Val: 0.8284, Test: 0.8354\n",
      "Epoch: 028, Loss: 0.5383, Val: 0.8305, Test: 0.8327\n",
      "Epoch: 029, Loss: 0.5427, Val: 0.8307, Test: 0.8324\n",
      "Epoch: 030, Loss: 0.5423, Val: 0.8305, Test: 0.8343\n",
      "Epoch: 031, Loss: 0.5435, Val: 0.8293, Test: 0.8356\n",
      "Epoch: 032, Loss: 0.5418, Val: 0.8308, Test: 0.8344\n",
      "Epoch: 033, Loss: 0.5408, Val: 0.8315, Test: 0.8321\n",
      "Epoch: 034, Loss: 0.5407, Val: 0.8312, Test: 0.8343\n",
      "Epoch: 035, Loss: 0.5491, Val: 0.8308, Test: 0.8357\n",
      "Epoch: 036, Loss: 0.5371, Val: 0.8309, Test: 0.8359\n",
      "Epoch: 037, Loss: 0.5373, Val: 0.8313, Test: 0.8361\n",
      "Epoch: 038, Loss: 0.5382, Val: 0.8312, Test: 0.8359\n",
      "Epoch: 039, Loss: 0.5359, Val: 0.8309, Test: 0.8367\n",
      "Epoch: 040, Loss: 0.5352, Val: 0.8310, Test: 0.8366\n",
      "Epoch: 041, Loss: 0.5393, Val: 0.8310, Test: 0.8366\n",
      "Epoch: 042, Loss: 0.5340, Val: 0.8309, Test: 0.8368\n",
      "Epoch: 043, Loss: 0.5343, Val: 0.8302, Test: 0.8370\n",
      "Epoch: 044, Loss: 0.5342, Val: 0.8309, Test: 0.8367\n",
      "Epoch: 045, Loss: 0.5425, Val: 0.8311, Test: 0.8368\n",
      "Epoch: 046, Loss: 0.5352, Val: 0.8306, Test: 0.8367\n",
      "Epoch: 047, Loss: 0.5372, Val: 0.8305, Test: 0.8368\n",
      "Epoch: 048, Loss: 0.5352, Val: 0.8308, Test: 0.8354\n",
      "Epoch: 049, Loss: 0.5334, Val: 0.8311, Test: 0.8361\n",
      "Epoch: 050, Loss: 0.5345, Val: 0.8307, Test: 0.8372\n",
      "Epoch: 051, Loss: 0.5384, Val: 0.8309, Test: 0.8368\n",
      "Epoch: 052, Loss: 0.5374, Val: 0.8317, Test: 0.8351\n",
      "Epoch: 053, Loss: 0.5324, Val: 0.8316, Test: 0.8358\n",
      "Epoch: 054, Loss: 0.5310, Val: 0.8311, Test: 0.8374\n",
      "Epoch: 055, Loss: 0.5336, Val: 0.8314, Test: 0.8376\n",
      "Epoch: 056, Loss: 0.5330, Val: 0.8320, Test: 0.8368\n",
      "Epoch: 057, Loss: 0.5384, Val: 0.8313, Test: 0.8369\n",
      "Epoch: 058, Loss: 0.5309, Val: 0.8305, Test: 0.8373\n",
      "Epoch: 059, Loss: 0.5351, Val: 0.8304, Test: 0.8374\n",
      "Epoch: 060, Loss: 0.5362, Val: 0.8317, Test: 0.8368\n",
      "Epoch: 061, Loss: 0.5354, Val: 0.8320, Test: 0.8373\n",
      "Epoch: 062, Loss: 0.5353, Val: 0.8309, Test: 0.8382\n",
      "Epoch: 063, Loss: 0.5348, Val: 0.8294, Test: 0.8383\n",
      "Epoch: 064, Loss: 0.5355, Val: 0.8320, Test: 0.8385\n",
      "Epoch: 065, Loss: 0.5311, Val: 0.8300, Test: 0.8357\n",
      "Epoch: 066, Loss: 0.5298, Val: 0.8325, Test: 0.8394\n",
      "Epoch: 067, Loss: 0.5298, Val: 0.8314, Test: 0.8396\n",
      "Epoch: 068, Loss: 0.5330, Val: 0.8326, Test: 0.8400\n",
      "Epoch: 069, Loss: 0.5312, Val: 0.8329, Test: 0.8398\n",
      "Epoch: 070, Loss: 0.5322, Val: 0.8325, Test: 0.8384\n",
      "Epoch: 071, Loss: 0.5303, Val: 0.8331, Test: 0.8395\n",
      "Epoch: 072, Loss: 0.5339, Val: 0.8289, Test: 0.8393\n",
      "Epoch: 073, Loss: 0.5266, Val: 0.8323, Test: 0.8395\n",
      "Epoch: 074, Loss: 0.5315, Val: 0.8324, Test: 0.8391\n",
      "Epoch: 075, Loss: 0.5260, Val: 0.8319, Test: 0.8381\n",
      "Epoch: 076, Loss: 0.5249, Val: 0.8322, Test: 0.8387\n",
      "Epoch: 077, Loss: 0.5289, Val: 0.8324, Test: 0.8386\n",
      "Epoch: 078, Loss: 0.5293, Val: 0.8326, Test: 0.8389\n",
      "Epoch: 079, Loss: 0.5255, Val: 0.8345, Test: 0.8398\n",
      "Epoch: 080, Loss: 0.5269, Val: 0.8352, Test: 0.8408\n",
      "Epoch: 081, Loss: 0.5173, Val: 0.8356, Test: 0.8416\n",
      "Epoch: 082, Loss: 0.5313, Val: 0.8344, Test: 0.8408\n",
      "Epoch: 083, Loss: 0.5184, Val: 0.8335, Test: 0.8399\n",
      "Epoch: 084, Loss: 0.5288, Val: 0.8337, Test: 0.8385\n",
      "Epoch: 085, Loss: 0.5199, Val: 0.8338, Test: 0.8386\n",
      "Epoch: 086, Loss: 0.5230, Val: 0.8331, Test: 0.8397\n",
      "Epoch: 087, Loss: 0.5204, Val: 0.8339, Test: 0.8411\n",
      "Epoch: 088, Loss: 0.5237, Val: 0.8345, Test: 0.8411\n",
      "Epoch: 089, Loss: 0.5183, Val: 0.8350, Test: 0.8410\n",
      "Epoch: 090, Loss: 0.5189, Val: 0.8351, Test: 0.8410\n",
      "Epoch: 091, Loss: 0.5202, Val: 0.8351, Test: 0.8410\n",
      "Epoch: 092, Loss: 0.5223, Val: 0.8353, Test: 0.8411\n",
      "Epoch: 093, Loss: 0.5174, Val: 0.8356, Test: 0.8415\n",
      "Epoch: 094, Loss: 0.5195, Val: 0.8351, Test: 0.8414\n",
      "Epoch: 095, Loss: 0.5101, Val: 0.8340, Test: 0.8411\n",
      "Epoch: 096, Loss: 0.5212, Val: 0.8327, Test: 0.8398\n",
      "Epoch: 097, Loss: 0.5160, Val: 0.8321, Test: 0.8392\n",
      "Epoch: 098, Loss: 0.5197, Val: 0.8326, Test: 0.8391\n",
      "Epoch: 099, Loss: 0.5167, Val: 0.8336, Test: 0.8395\n",
      "Epoch: 100, Loss: 0.5104, Val: 0.8360, Test: 0.8411\n",
      "Final Test: 0.8411\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.nn import GCNConv\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from torch_geometric.utils import negative_sampling\n",
    "\n",
    "\n",
    "model = Net(9, 128, 64).to(device)\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    x_train = torch.concatenate((train_data.x, train_data.x_glase), axis=1)\n",
    "    z = model.encode(x_train, train_data.edge_index)\n",
    "\n",
    "    # We perform a new round of negative sampling for every training epoch:\n",
    "    neg_edge_index = negative_sampling(\n",
    "        edge_index=train_data.edge_index, num_nodes=train_data.num_nodes,\n",
    "        num_neg_samples=train_data.edge_label_index.size(1), method='sparse')\n",
    "\n",
    "    edge_label_index = torch.cat(\n",
    "        [train_data.edge_label_index, neg_edge_index],\n",
    "        dim=-1,\n",
    "    )\n",
    "    edge_label = torch.cat([\n",
    "        train_data.edge_label,\n",
    "        train_data.edge_label.new_zeros(neg_edge_index.size(1))\n",
    "    ], dim=0)\n",
    "\n",
    "    out = model.decode(z, edge_label_index).view(-1)\n",
    "    loss = criterion(out, edge_label)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(data):\n",
    "    model.eval()\n",
    "    x_test = torch.concatenate((data.x, data.x_glase), axis=1)\n",
    "    z = model.encode(x_test, data.edge_index)\n",
    "    out = model.decode(z, data.edge_label_index).view(-1).sigmoid()\n",
    "    return roc_auc_score(data.edge_label.cpu().numpy(), out.cpu().numpy())\n",
    "\n",
    "\n",
    "best_val_auc = final_test_auc = 0\n",
    "for epoch in range(1, 101):\n",
    "    loss = train()\n",
    "    val_auc = test(val_data)\n",
    "    test_auc = test(test_data)\n",
    "    if val_auc > best_val_auc:\n",
    "        best_val_auc = val_auc\n",
    "        final_test_auc = test_auc\n",
    "    print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Val: {val_auc:.4f}, '\n",
    "          f'Test: {test_auc:.4f}')\n",
    "\n",
    "print(f'Final Test: {final_test_auc:.4f}')\n",
    "\n",
    "x_test = torch.concatenate((test_data.x, test_data.x_glase), axis=1)\n",
    "z = model.encode(x_test, test_data.edge_index)\n",
    "final_edge_index = model.decode_all(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8558)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Predict on entire masked graph\n",
    "x_test = torch.concatenate((data.x, data.x_glase), axis=1)\n",
    "z = model.encode(x_test, data.edge_index)\n",
    "final_edge_index = model.decode_all(z)\n",
    "\n",
    "\n",
    "predicted_adj = to_dense_adj(final_edge_index).squeeze(0).to('cpu')\n",
    "(adj_matrix[senadores_no_presentes][:,n_P1+n_P2:]==predicted_adj[senadores_no_presentes][:,n_P1+n_P2:]).sum() / (n_P1_np+n_P2_np) / 230"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vector of ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.],\n",
       "        ...,\n",
       "        [1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "ones_features=torch.ones([410, 5])\n",
    "ones_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Split Train, Val, Test\n",
    "from torch_geometric.data import Data\n",
    "import torch_geometric.transforms as T\n",
    "\n",
    "device = 'cuda'\n",
    "\n",
    "masked_edge_index = masked_adj.nonzero().t().contiguous()\n",
    "\n",
    "data = Data(x=random_features.float(), x_ase=x_ase, x_glase=x_glase, edge_index=masked_edge_index)\n",
    "\n",
    "transform = T.Compose([\n",
    "    # T.NormalizeFeatures(),\n",
    "    T.ToDevice(device),\n",
    "    T.RandomLinkSplit(num_val=0.05, num_test=0.1, is_undirected=True,\n",
    "                      add_negative_train_samples=False),\n",
    "])\n",
    "\n",
    "\n",
    "train_data, val_data, test_data = transform(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GCN Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.6809, Val: 0.7945, Test: 0.7740\n",
      "Epoch: 002, Loss: 0.6746, Val: 0.7971, Test: 0.7769\n",
      "Epoch: 003, Loss: 0.6950, Val: 0.7963, Test: 0.7767\n",
      "Epoch: 004, Loss: 0.6680, Val: 0.7958, Test: 0.7767\n",
      "Epoch: 005, Loss: 0.6728, Val: 0.7960, Test: 0.7770\n",
      "Epoch: 006, Loss: 0.6740, Val: 0.7967, Test: 0.7769\n",
      "Epoch: 007, Loss: 0.6702, Val: 0.7971, Test: 0.7770\n",
      "Epoch: 008, Loss: 0.6666, Val: 0.7976, Test: 0.7770\n",
      "Epoch: 009, Loss: 0.6665, Val: 0.7977, Test: 0.7771\n",
      "Epoch: 010, Loss: 0.6687, Val: 0.7976, Test: 0.7770\n",
      "Epoch: 011, Loss: 0.6626, Val: 0.7970, Test: 0.7770\n",
      "Epoch: 012, Loss: 0.6600, Val: 0.7965, Test: 0.7766\n",
      "Epoch: 013, Loss: 0.6582, Val: 0.7964, Test: 0.7763\n",
      "Epoch: 014, Loss: 0.6561, Val: 0.7963, Test: 0.7763\n",
      "Epoch: 015, Loss: 0.6524, Val: 0.7970, Test: 0.7766\n",
      "Epoch: 016, Loss: 0.6488, Val: 0.7971, Test: 0.7768\n",
      "Epoch: 017, Loss: 0.6482, Val: 0.7968, Test: 0.7768\n",
      "Epoch: 018, Loss: 0.6453, Val: 0.7962, Test: 0.7761\n",
      "Epoch: 019, Loss: 0.6414, Val: 0.7954, Test: 0.7750\n",
      "Epoch: 020, Loss: 0.6410, Val: 0.7946, Test: 0.7740\n",
      "Epoch: 021, Loss: 0.6389, Val: 0.7941, Test: 0.7734\n",
      "Epoch: 022, Loss: 0.6380, Val: 0.7941, Test: 0.7734\n",
      "Epoch: 023, Loss: 0.6368, Val: 0.7941, Test: 0.7736\n",
      "Epoch: 024, Loss: 0.6316, Val: 0.7937, Test: 0.7735\n",
      "Epoch: 025, Loss: 0.6322, Val: 0.7924, Test: 0.7723\n",
      "Epoch: 026, Loss: 0.6282, Val: 0.7901, Test: 0.7705\n",
      "Epoch: 027, Loss: 0.6278, Val: 0.7879, Test: 0.7686\n",
      "Epoch: 028, Loss: 0.6280, Val: 0.7867, Test: 0.7676\n",
      "Epoch: 029, Loss: 0.6200, Val: 0.7880, Test: 0.7687\n",
      "Epoch: 030, Loss: 0.6225, Val: 0.7870, Test: 0.7681\n",
      "Epoch: 031, Loss: 0.6191, Val: 0.7841, Test: 0.7654\n",
      "Epoch: 032, Loss: 0.6198, Val: 0.7795, Test: 0.7606\n",
      "Epoch: 033, Loss: 0.6162, Val: 0.7792, Test: 0.7593\n",
      "Epoch: 034, Loss: 0.6162, Val: 0.7797, Test: 0.7602\n",
      "Epoch: 035, Loss: 0.6167, Val: 0.7796, Test: 0.7597\n",
      "Epoch: 036, Loss: 0.6155, Val: 0.7771, Test: 0.7559\n",
      "Epoch: 037, Loss: 0.6115, Val: 0.7726, Test: 0.7534\n",
      "Epoch: 038, Loss: 0.6128, Val: 0.7725, Test: 0.7533\n",
      "Epoch: 039, Loss: 0.6134, Val: 0.7727, Test: 0.7532\n",
      "Epoch: 040, Loss: 0.6102, Val: 0.7716, Test: 0.7520\n",
      "Epoch: 041, Loss: 0.6098, Val: 0.7685, Test: 0.7504\n",
      "Epoch: 042, Loss: 0.6141, Val: 0.7634, Test: 0.7480\n",
      "Epoch: 043, Loss: 0.6078, Val: 0.7659, Test: 0.7496\n",
      "Epoch: 044, Loss: 0.6050, Val: 0.7683, Test: 0.7503\n",
      "Epoch: 045, Loss: 0.6045, Val: 0.7629, Test: 0.7483\n",
      "Epoch: 046, Loss: 0.6052, Val: 0.7581, Test: 0.7441\n",
      "Epoch: 047, Loss: 0.6005, Val: 0.7597, Test: 0.7460\n",
      "Epoch: 048, Loss: 0.5993, Val: 0.7634, Test: 0.7492\n",
      "Epoch: 049, Loss: 0.6076, Val: 0.7573, Test: 0.7432\n",
      "Epoch: 050, Loss: 0.6031, Val: 0.7543, Test: 0.7386\n",
      "Epoch: 051, Loss: 0.6033, Val: 0.7571, Test: 0.7430\n",
      "Epoch: 052, Loss: 0.6035, Val: 0.7579, Test: 0.7444\n",
      "Epoch: 053, Loss: 0.5991, Val: 0.7564, Test: 0.7415\n",
      "Epoch: 054, Loss: 0.5981, Val: 0.7547, Test: 0.7385\n",
      "Epoch: 055, Loss: 0.5979, Val: 0.7552, Test: 0.7394\n",
      "Epoch: 056, Loss: 0.6024, Val: 0.7555, Test: 0.7399\n",
      "Epoch: 057, Loss: 0.5980, Val: 0.7550, Test: 0.7391\n",
      "Epoch: 058, Loss: 0.6022, Val: 0.7527, Test: 0.7359\n",
      "Epoch: 059, Loss: 0.5947, Val: 0.7543, Test: 0.7376\n",
      "Epoch: 060, Loss: 0.5983, Val: 0.7546, Test: 0.7383\n",
      "Epoch: 061, Loss: 0.5973, Val: 0.7534, Test: 0.7362\n",
      "Epoch: 062, Loss: 0.5967, Val: 0.7524, Test: 0.7357\n",
      "Epoch: 063, Loss: 0.5983, Val: 0.7528, Test: 0.7359\n",
      "Epoch: 064, Loss: 0.5984, Val: 0.7514, Test: 0.7349\n",
      "Epoch: 065, Loss: 0.6021, Val: 0.7502, Test: 0.7339\n",
      "Epoch: 066, Loss: 0.5959, Val: 0.7530, Test: 0.7361\n",
      "Epoch: 067, Loss: 0.5956, Val: 0.7529, Test: 0.7360\n",
      "Epoch: 068, Loss: 0.5951, Val: 0.7499, Test: 0.7335\n",
      "Epoch: 069, Loss: 0.6007, Val: 0.7484, Test: 0.7325\n",
      "Epoch: 070, Loss: 0.6032, Val: 0.7496, Test: 0.7334\n",
      "Epoch: 071, Loss: 0.5987, Val: 0.7513, Test: 0.7349\n",
      "Epoch: 072, Loss: 0.5915, Val: 0.7522, Test: 0.7355\n",
      "Epoch: 073, Loss: 0.6035, Val: 0.7461, Test: 0.7312\n",
      "Epoch: 074, Loss: 0.6034, Val: 0.7478, Test: 0.7320\n",
      "Epoch: 075, Loss: 0.6028, Val: 0.7516, Test: 0.7348\n",
      "Epoch: 076, Loss: 0.5984, Val: 0.7499, Test: 0.7336\n",
      "Epoch: 077, Loss: 0.5924, Val: 0.7488, Test: 0.7330\n",
      "Epoch: 078, Loss: 0.5909, Val: 0.7511, Test: 0.7345\n",
      "Epoch: 079, Loss: 0.5995, Val: 0.7481, Test: 0.7325\n",
      "Epoch: 080, Loss: 0.5948, Val: 0.7491, Test: 0.7331\n",
      "Epoch: 081, Loss: 0.5978, Val: 0.7497, Test: 0.7334\n",
      "Epoch: 082, Loss: 0.5958, Val: 0.7495, Test: 0.7333\n",
      "Epoch: 083, Loss: 0.6003, Val: 0.7482, Test: 0.7326\n",
      "Epoch: 084, Loss: 0.5914, Val: 0.7509, Test: 0.7343\n",
      "Epoch: 085, Loss: 0.6010, Val: 0.7472, Test: 0.7317\n",
      "Epoch: 086, Loss: 0.5918, Val: 0.7493, Test: 0.7331\n",
      "Epoch: 087, Loss: 0.5970, Val: 0.7500, Test: 0.7336\n",
      "Epoch: 088, Loss: 0.6014, Val: 0.7469, Test: 0.7315\n",
      "Epoch: 089, Loss: 0.5973, Val: 0.7492, Test: 0.7330\n",
      "Epoch: 090, Loss: 0.6049, Val: 0.7474, Test: 0.7318\n",
      "Epoch: 091, Loss: 0.6010, Val: 0.7474, Test: 0.7319\n",
      "Epoch: 092, Loss: 0.6019, Val: 0.7491, Test: 0.7329\n",
      "Epoch: 093, Loss: 0.5981, Val: 0.7498, Test: 0.7334\n",
      "Epoch: 094, Loss: 0.5965, Val: 0.7486, Test: 0.7328\n",
      "Epoch: 095, Loss: 0.5989, Val: 0.7470, Test: 0.7317\n",
      "Epoch: 096, Loss: 0.6064, Val: 0.7469, Test: 0.7316\n",
      "Epoch: 097, Loss: 0.5939, Val: 0.7527, Test: 0.7356\n",
      "Epoch: 098, Loss: 0.6036, Val: 0.7470, Test: 0.7317\n",
      "Epoch: 099, Loss: 0.5990, Val: 0.7466, Test: 0.7312\n",
      "Epoch: 100, Loss: 0.6001, Val: 0.7519, Test: 0.7352\n",
      "Final Test: 0.7771\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.nn import GCNConv\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from torch_geometric.utils import negative_sampling\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, out_channels)\n",
    "\n",
    "    def encode(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        return self.conv2(x, edge_index)\n",
    "\n",
    "    def decode(self, z, edge_label_index):\n",
    "        return (z[edge_label_index[0]] * z[edge_label_index[1]]).sum(dim=-1)\n",
    "\n",
    "    def decode_all(self, z):\n",
    "        prob_adj = z @ z.t()\n",
    "        return (prob_adj > 0).nonzero(as_tuple=False).t()\n",
    "\n",
    "\n",
    "model = Net(5, 128, 64).to(device)\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    z = model.encode(train_data.x, train_data.edge_index)\n",
    "\n",
    "    # We perform a new round of negative sampling for every training epoch:\n",
    "    neg_edge_index = negative_sampling(\n",
    "        edge_index=train_data.edge_index, num_nodes=train_data.num_nodes,\n",
    "        num_neg_samples=train_data.edge_label_index.size(1), method='sparse')\n",
    "\n",
    "    edge_label_index = torch.cat(\n",
    "        [train_data.edge_label_index, neg_edge_index],\n",
    "        dim=-1,\n",
    "    )\n",
    "    edge_label = torch.cat([\n",
    "        train_data.edge_label,\n",
    "        train_data.edge_label.new_zeros(neg_edge_index.size(1))\n",
    "    ], dim=0)\n",
    "\n",
    "    out = model.decode(z, edge_label_index).view(-1)\n",
    "    loss = criterion(out, edge_label)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(data):\n",
    "    model.eval()\n",
    "    z = model.encode(data.x, data.edge_index)\n",
    "    out = model.decode(z, data.edge_label_index).view(-1).sigmoid()\n",
    "    return roc_auc_score(data.edge_label.cpu().numpy(), out.cpu().numpy())\n",
    "\n",
    "\n",
    "best_val_auc = final_test_auc = 0\n",
    "for epoch in range(1, 101):\n",
    "    loss = train()\n",
    "    val_auc = test(val_data)\n",
    "    test_auc = test(test_data)\n",
    "    if val_auc > best_val_auc:\n",
    "        best_val_auc = val_auc\n",
    "        final_test_auc = test_auc\n",
    "    print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Val: {val_auc:.4f}, '\n",
    "          f'Test: {test_auc:.4f}')\n",
    "\n",
    "print(f'Final Test: {final_test_auc:.4f}')\n",
    "\n",
    "z = model.encode(test_data.x, test_data.edge_index)\n",
    "final_edge_index = model.decode_all(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5545)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Predict on entire masked graph\n",
    "\n",
    "z = model.encode(data.x, data.edge_index)\n",
    "final_edge_index = model.decode_all(z)\n",
    "\n",
    "\n",
    "predicted_adj = to_dense_adj(final_edge_index).squeeze(0).to('cpu')\n",
    "(adj_matrix[senadores_no_presentes][:,n_P1+n_P2:]==predicted_adj[senadores_no_presentes][:,n_P1+n_P2:]).sum() / (n_P1_np+n_P2_np) / 230\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ASE Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.6694, Val: 0.8427, Test: 0.8247\n",
      "Epoch: 002, Loss: 0.6670, Val: 0.8461, Test: 0.8198\n",
      "Epoch: 003, Loss: 0.6483, Val: 0.8730, Test: 0.8557\n",
      "Epoch: 004, Loss: 0.6304, Val: 0.8706, Test: 0.8652\n",
      "Epoch: 005, Loss: 0.6054, Val: 0.8490, Test: 0.8508\n",
      "Epoch: 006, Loss: 0.5772, Val: 0.8428, Test: 0.8379\n",
      "Epoch: 007, Loss: 0.5562, Val: 0.8371, Test: 0.8408\n",
      "Epoch: 008, Loss: 0.5409, Val: 0.8396, Test: 0.8331\n",
      "Epoch: 009, Loss: 0.5562, Val: 0.8187, Test: 0.8304\n",
      "Epoch: 010, Loss: 0.5673, Val: 0.8372, Test: 0.8344\n",
      "Epoch: 011, Loss: 0.5494, Val: 0.8351, Test: 0.8300\n",
      "Epoch: 012, Loss: 0.5546, Val: 0.8293, Test: 0.8346\n",
      "Epoch: 013, Loss: 0.5419, Val: 0.8241, Test: 0.8326\n",
      "Epoch: 014, Loss: 0.5455, Val: 0.8312, Test: 0.8298\n",
      "Epoch: 015, Loss: 0.5385, Val: 0.8334, Test: 0.8291\n",
      "Epoch: 016, Loss: 0.5485, Val: 0.8347, Test: 0.8319\n",
      "Epoch: 017, Loss: 0.5405, Val: 0.8370, Test: 0.8389\n",
      "Epoch: 018, Loss: 0.5395, Val: 0.8387, Test: 0.8411\n",
      "Epoch: 019, Loss: 0.5379, Val: 0.8420, Test: 0.8413\n",
      "Epoch: 020, Loss: 0.5321, Val: 0.8434, Test: 0.8402\n",
      "Epoch: 021, Loss: 0.5367, Val: 0.8419, Test: 0.8406\n",
      "Epoch: 022, Loss: 0.5285, Val: 0.8393, Test: 0.8406\n",
      "Epoch: 023, Loss: 0.5305, Val: 0.8394, Test: 0.8396\n",
      "Epoch: 024, Loss: 0.5324, Val: 0.8394, Test: 0.8375\n",
      "Epoch: 025, Loss: 0.5272, Val: 0.8380, Test: 0.8361\n",
      "Epoch: 026, Loss: 0.5289, Val: 0.8369, Test: 0.8372\n",
      "Epoch: 027, Loss: 0.5339, Val: 0.8362, Test: 0.8372\n",
      "Epoch: 028, Loss: 0.5343, Val: 0.8365, Test: 0.8359\n",
      "Epoch: 029, Loss: 0.5307, Val: 0.8370, Test: 0.8365\n",
      "Epoch: 030, Loss: 0.5255, Val: 0.8385, Test: 0.8380\n",
      "Epoch: 031, Loss: 0.5264, Val: 0.8394, Test: 0.8382\n",
      "Epoch: 032, Loss: 0.5333, Val: 0.8406, Test: 0.8386\n",
      "Epoch: 033, Loss: 0.5338, Val: 0.8401, Test: 0.8414\n",
      "Epoch: 034, Loss: 0.5304, Val: 0.8378, Test: 0.8414\n",
      "Epoch: 035, Loss: 0.5370, Val: 0.8396, Test: 0.8403\n",
      "Epoch: 036, Loss: 0.5270, Val: 0.8402, Test: 0.8384\n",
      "Epoch: 037, Loss: 0.5256, Val: 0.8398, Test: 0.8391\n",
      "Epoch: 038, Loss: 0.5278, Val: 0.8387, Test: 0.8402\n",
      "Epoch: 039, Loss: 0.5293, Val: 0.8394, Test: 0.8409\n",
      "Epoch: 040, Loss: 0.5255, Val: 0.8407, Test: 0.8412\n",
      "Epoch: 041, Loss: 0.5266, Val: 0.8415, Test: 0.8411\n",
      "Epoch: 042, Loss: 0.5260, Val: 0.8415, Test: 0.8435\n",
      "Epoch: 043, Loss: 0.5266, Val: 0.8409, Test: 0.8433\n",
      "Epoch: 044, Loss: 0.5165, Val: 0.8407, Test: 0.8423\n",
      "Epoch: 045, Loss: 0.5242, Val: 0.8406, Test: 0.8405\n",
      "Epoch: 046, Loss: 0.5349, Val: 0.8396, Test: 0.8413\n",
      "Epoch: 047, Loss: 0.5236, Val: 0.8394, Test: 0.8411\n",
      "Epoch: 048, Loss: 0.5253, Val: 0.8397, Test: 0.8420\n",
      "Epoch: 049, Loss: 0.5207, Val: 0.8413, Test: 0.8439\n",
      "Epoch: 050, Loss: 0.5283, Val: 0.8423, Test: 0.8449\n",
      "Epoch: 051, Loss: 0.5120, Val: 0.8430, Test: 0.8454\n",
      "Epoch: 052, Loss: 0.5232, Val: 0.8420, Test: 0.8448\n",
      "Epoch: 053, Loss: 0.5241, Val: 0.8398, Test: 0.8429\n",
      "Epoch: 054, Loss: 0.5202, Val: 0.8399, Test: 0.8421\n",
      "Epoch: 055, Loss: 0.5231, Val: 0.8401, Test: 0.8418\n",
      "Epoch: 056, Loss: 0.5229, Val: 0.8410, Test: 0.8437\n",
      "Epoch: 057, Loss: 0.5227, Val: 0.8418, Test: 0.8455\n",
      "Epoch: 058, Loss: 0.5235, Val: 0.8434, Test: 0.8457\n",
      "Epoch: 059, Loss: 0.5211, Val: 0.8426, Test: 0.8438\n",
      "Epoch: 060, Loss: 0.5212, Val: 0.8387, Test: 0.8423\n",
      "Epoch: 061, Loss: 0.5222, Val: 0.8366, Test: 0.8415\n",
      "Epoch: 062, Loss: 0.5236, Val: 0.8398, Test: 0.8419\n",
      "Epoch: 063, Loss: 0.5172, Val: 0.8426, Test: 0.8440\n",
      "Epoch: 064, Loss: 0.5229, Val: 0.8425, Test: 0.8459\n",
      "Epoch: 065, Loss: 0.5181, Val: 0.8393, Test: 0.8442\n",
      "Epoch: 066, Loss: 0.5192, Val: 0.8365, Test: 0.8404\n",
      "Epoch: 067, Loss: 0.5242, Val: 0.8374, Test: 0.8375\n",
      "Epoch: 068, Loss: 0.5144, Val: 0.8413, Test: 0.8424\n",
      "Epoch: 069, Loss: 0.5176, Val: 0.8424, Test: 0.8468\n",
      "Epoch: 070, Loss: 0.5127, Val: 0.8403, Test: 0.8447\n",
      "Epoch: 071, Loss: 0.5162, Val: 0.8377, Test: 0.8389\n",
      "Epoch: 072, Loss: 0.5206, Val: 0.8352, Test: 0.8350\n",
      "Epoch: 073, Loss: 0.5100, Val: 0.8369, Test: 0.8406\n",
      "Epoch: 074, Loss: 0.5168, Val: 0.8416, Test: 0.8451\n",
      "Epoch: 075, Loss: 0.5227, Val: 0.8432, Test: 0.8438\n",
      "Epoch: 076, Loss: 0.5147, Val: 0.8370, Test: 0.8375\n",
      "Epoch: 077, Loss: 0.5135, Val: 0.8340, Test: 0.8357\n",
      "Epoch: 078, Loss: 0.5137, Val: 0.8375, Test: 0.8403\n",
      "Epoch: 079, Loss: 0.5244, Val: 0.8419, Test: 0.8423\n",
      "Epoch: 080, Loss: 0.5147, Val: 0.8405, Test: 0.8402\n",
      "Epoch: 081, Loss: 0.5160, Val: 0.8349, Test: 0.8369\n",
      "Epoch: 082, Loss: 0.5171, Val: 0.8325, Test: 0.8349\n",
      "Epoch: 083, Loss: 0.5213, Val: 0.8350, Test: 0.8360\n",
      "Epoch: 084, Loss: 0.5139, Val: 0.8397, Test: 0.8391\n",
      "Epoch: 085, Loss: 0.5176, Val: 0.8366, Test: 0.8368\n",
      "Epoch: 086, Loss: 0.5097, Val: 0.8338, Test: 0.8341\n",
      "Epoch: 087, Loss: 0.5115, Val: 0.8325, Test: 0.8341\n",
      "Epoch: 088, Loss: 0.5097, Val: 0.8360, Test: 0.8372\n",
      "Epoch: 089, Loss: 0.5088, Val: 0.8430, Test: 0.8408\n",
      "Epoch: 090, Loss: 0.5093, Val: 0.8414, Test: 0.8392\n",
      "Epoch: 091, Loss: 0.5165, Val: 0.8356, Test: 0.8356\n",
      "Epoch: 092, Loss: 0.5064, Val: 0.8360, Test: 0.8366\n",
      "Epoch: 093, Loss: 0.5091, Val: 0.8383, Test: 0.8386\n",
      "Epoch: 094, Loss: 0.5099, Val: 0.8413, Test: 0.8386\n",
      "Epoch: 095, Loss: 0.5095, Val: 0.8361, Test: 0.8346\n",
      "Epoch: 096, Loss: 0.5176, Val: 0.8313, Test: 0.8330\n",
      "Epoch: 097, Loss: 0.5161, Val: 0.8328, Test: 0.8336\n",
      "Epoch: 098, Loss: 0.5106, Val: 0.8366, Test: 0.8357\n",
      "Epoch: 099, Loss: 0.5068, Val: 0.8365, Test: 0.8345\n",
      "Epoch: 100, Loss: 0.5118, Val: 0.8319, Test: 0.8317\n",
      "Final Test: 0.8557\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.nn import GCNConv\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from torch_geometric.utils import negative_sampling\n",
    "\n",
    "\n",
    "model = Net(9, 128, 64).to(device)\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    x_train = torch.concatenate((train_data.x, train_data.x_ase), axis=1)\n",
    "    z = model.encode(x_train, train_data.edge_index)\n",
    "\n",
    "    # We perform a new round of negative sampling for every training epoch:\n",
    "    neg_edge_index = negative_sampling(\n",
    "        edge_index=train_data.edge_index, num_nodes=train_data.num_nodes,\n",
    "        num_neg_samples=train_data.edge_label_index.size(1), method='sparse')\n",
    "\n",
    "    edge_label_index = torch.cat(\n",
    "        [train_data.edge_label_index, neg_edge_index],\n",
    "        dim=-1,\n",
    "    )\n",
    "    edge_label = torch.cat([\n",
    "        train_data.edge_label,\n",
    "        train_data.edge_label.new_zeros(neg_edge_index.size(1))\n",
    "    ], dim=0)\n",
    "\n",
    "    out = model.decode(z, edge_label_index).view(-1)\n",
    "    loss = criterion(out, edge_label)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(data):\n",
    "    model.eval()\n",
    "    x_test = torch.concatenate((data.x, data.x_ase), axis=1)\n",
    "    z = model.encode(x_test, data.edge_index)\n",
    "    out = model.decode(z, data.edge_label_index).view(-1).sigmoid()\n",
    "    return roc_auc_score(data.edge_label.cpu().numpy(), out.cpu().numpy())\n",
    "\n",
    "\n",
    "best_val_auc = final_test_auc = 0\n",
    "for epoch in range(1, 101):\n",
    "    loss = train()\n",
    "    val_auc = test(val_data)\n",
    "    test_auc = test(test_data)\n",
    "    if val_auc > best_val_auc:\n",
    "        best_val_auc = val_auc\n",
    "        final_test_auc = test_auc\n",
    "    print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Val: {val_auc:.4f}, '\n",
    "          f'Test: {test_auc:.4f}')\n",
    "\n",
    "print(f'Final Test: {final_test_auc:.4f}')\n",
    "\n",
    "x_test = torch.concatenate((test_data.x, test_data.x_ase), axis=1)\n",
    "z = model.encode(x_test, test_data.edge_index)\n",
    "final_edge_index = model.decode_all(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8357)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Predict on entire masked graph\n",
    "x_test = torch.concatenate((data.x, data.x_ase), axis=1)\n",
    "z = model.encode(x_test, data.edge_index)\n",
    "final_edge_index = model.decode_all(z)\n",
    "\n",
    "\n",
    "predicted_adj = to_dense_adj(final_edge_index).squeeze(0).to('cpu')\n",
    "(adj_matrix[senadores_no_presentes][:,n_P1+n_P2:]==predicted_adj[senadores_no_presentes][:,n_P1+n_P2:]).sum() / (n_P1_np+n_P2_np) / 230"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GLASE Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.8382, Val: 0.6897, Test: 0.7031\n",
      "Epoch: 002, Loss: 0.6994, Val: 0.7442, Test: 0.7525\n",
      "Epoch: 003, Loss: 0.6994, Val: 0.7943, Test: 0.7836\n",
      "Epoch: 004, Loss: 0.6782, Val: 0.8038, Test: 0.7913\n",
      "Epoch: 005, Loss: 0.6596, Val: 0.8057, Test: 0.7909\n",
      "Epoch: 006, Loss: 0.6519, Val: 0.7889, Test: 0.7664\n",
      "Epoch: 007, Loss: 0.6490, Val: 0.7955, Test: 0.7749\n",
      "Epoch: 008, Loss: 0.6417, Val: 0.8108, Test: 0.7998\n",
      "Epoch: 009, Loss: 0.6352, Val: 0.8050, Test: 0.7956\n",
      "Epoch: 010, Loss: 0.6222, Val: 0.7920, Test: 0.7842\n",
      "Epoch: 011, Loss: 0.6096, Val: 0.7921, Test: 0.7866\n",
      "Epoch: 012, Loss: 0.6048, Val: 0.8015, Test: 0.7905\n",
      "Epoch: 013, Loss: 0.5982, Val: 0.8124, Test: 0.8027\n",
      "Epoch: 014, Loss: 0.5842, Val: 0.8129, Test: 0.8052\n",
      "Epoch: 015, Loss: 0.5827, Val: 0.8105, Test: 0.8022\n",
      "Epoch: 016, Loss: 0.5685, Val: 0.8095, Test: 0.8089\n",
      "Epoch: 017, Loss: 0.5680, Val: 0.8197, Test: 0.8168\n",
      "Epoch: 018, Loss: 0.5601, Val: 0.8284, Test: 0.8236\n",
      "Epoch: 019, Loss: 0.5519, Val: 0.8314, Test: 0.8238\n",
      "Epoch: 020, Loss: 0.5501, Val: 0.8363, Test: 0.8329\n",
      "Epoch: 021, Loss: 0.5432, Val: 0.8355, Test: 0.8381\n",
      "Epoch: 022, Loss: 0.5427, Val: 0.8339, Test: 0.8378\n",
      "Epoch: 023, Loss: 0.5417, Val: 0.8371, Test: 0.8367\n",
      "Epoch: 024, Loss: 0.5428, Val: 0.8355, Test: 0.8318\n",
      "Epoch: 025, Loss: 0.5345, Val: 0.8341, Test: 0.8315\n",
      "Epoch: 026, Loss: 0.5386, Val: 0.8324, Test: 0.8325\n",
      "Epoch: 027, Loss: 0.5446, Val: 0.8298, Test: 0.8336\n",
      "Epoch: 028, Loss: 0.5400, Val: 0.8325, Test: 0.8305\n",
      "Epoch: 029, Loss: 0.5448, Val: 0.8318, Test: 0.8285\n",
      "Epoch: 030, Loss: 0.5431, Val: 0.8326, Test: 0.8296\n",
      "Epoch: 031, Loss: 0.5399, Val: 0.8297, Test: 0.8351\n",
      "Epoch: 032, Loss: 0.5385, Val: 0.8306, Test: 0.8361\n",
      "Epoch: 033, Loss: 0.5415, Val: 0.8351, Test: 0.8334\n",
      "Epoch: 034, Loss: 0.5325, Val: 0.8363, Test: 0.8329\n",
      "Epoch: 035, Loss: 0.5383, Val: 0.8367, Test: 0.8360\n",
      "Epoch: 036, Loss: 0.5328, Val: 0.8359, Test: 0.8379\n",
      "Epoch: 037, Loss: 0.5344, Val: 0.8351, Test: 0.8382\n",
      "Epoch: 038, Loss: 0.5347, Val: 0.8365, Test: 0.8379\n",
      "Epoch: 039, Loss: 0.5360, Val: 0.8374, Test: 0.8368\n",
      "Epoch: 040, Loss: 0.5364, Val: 0.8377, Test: 0.8368\n",
      "Epoch: 041, Loss: 0.5357, Val: 0.8379, Test: 0.8375\n",
      "Epoch: 042, Loss: 0.5351, Val: 0.8378, Test: 0.8367\n",
      "Epoch: 043, Loss: 0.5306, Val: 0.8374, Test: 0.8367\n",
      "Epoch: 044, Loss: 0.5339, Val: 0.8374, Test: 0.8355\n",
      "Epoch: 045, Loss: 0.5320, Val: 0.8373, Test: 0.8356\n",
      "Epoch: 046, Loss: 0.5332, Val: 0.8344, Test: 0.8385\n",
      "Epoch: 047, Loss: 0.5310, Val: 0.8351, Test: 0.8381\n",
      "Epoch: 048, Loss: 0.5361, Val: 0.8373, Test: 0.8347\n",
      "Epoch: 049, Loss: 0.5226, Val: 0.8377, Test: 0.8351\n",
      "Epoch: 050, Loss: 0.5310, Val: 0.8355, Test: 0.8385\n",
      "Epoch: 051, Loss: 0.5310, Val: 0.8345, Test: 0.8385\n",
      "Epoch: 052, Loss: 0.5344, Val: 0.8367, Test: 0.8369\n",
      "Epoch: 053, Loss: 0.5405, Val: 0.8370, Test: 0.8361\n",
      "Epoch: 054, Loss: 0.5395, Val: 0.8372, Test: 0.8380\n",
      "Epoch: 055, Loss: 0.5318, Val: 0.8368, Test: 0.8400\n",
      "Epoch: 056, Loss: 0.5276, Val: 0.8392, Test: 0.8398\n",
      "Epoch: 057, Loss: 0.5271, Val: 0.8397, Test: 0.8393\n",
      "Epoch: 058, Loss: 0.5280, Val: 0.8398, Test: 0.8394\n",
      "Epoch: 059, Loss: 0.5278, Val: 0.8388, Test: 0.8412\n",
      "Epoch: 060, Loss: 0.5306, Val: 0.8370, Test: 0.8409\n",
      "Epoch: 061, Loss: 0.5394, Val: 0.8381, Test: 0.8396\n",
      "Epoch: 062, Loss: 0.5346, Val: 0.8382, Test: 0.8374\n",
      "Epoch: 063, Loss: 0.5301, Val: 0.8385, Test: 0.8390\n",
      "Epoch: 064, Loss: 0.5259, Val: 0.8385, Test: 0.8406\n",
      "Epoch: 065, Loss: 0.5335, Val: 0.8381, Test: 0.8417\n",
      "Epoch: 066, Loss: 0.5341, Val: 0.8371, Test: 0.8415\n",
      "Epoch: 067, Loss: 0.5259, Val: 0.8381, Test: 0.8406\n",
      "Epoch: 068, Loss: 0.5257, Val: 0.8388, Test: 0.8376\n",
      "Epoch: 069, Loss: 0.5279, Val: 0.8390, Test: 0.8389\n",
      "Epoch: 070, Loss: 0.5284, Val: 0.8385, Test: 0.8413\n",
      "Epoch: 071, Loss: 0.5318, Val: 0.8383, Test: 0.8422\n",
      "Epoch: 072, Loss: 0.5247, Val: 0.8399, Test: 0.8421\n",
      "Epoch: 073, Loss: 0.5313, Val: 0.8406, Test: 0.8415\n",
      "Epoch: 074, Loss: 0.5235, Val: 0.8403, Test: 0.8419\n",
      "Epoch: 075, Loss: 0.5249, Val: 0.8392, Test: 0.8427\n",
      "Epoch: 076, Loss: 0.5233, Val: 0.8387, Test: 0.8429\n",
      "Epoch: 077, Loss: 0.5222, Val: 0.8398, Test: 0.8422\n",
      "Epoch: 078, Loss: 0.5194, Val: 0.8402, Test: 0.8422\n",
      "Epoch: 079, Loss: 0.5312, Val: 0.8387, Test: 0.8421\n",
      "Epoch: 080, Loss: 0.5297, Val: 0.8390, Test: 0.8425\n",
      "Epoch: 081, Loss: 0.5162, Val: 0.8415, Test: 0.8437\n",
      "Epoch: 082, Loss: 0.5233, Val: 0.8410, Test: 0.8448\n",
      "Epoch: 083, Loss: 0.5206, Val: 0.8397, Test: 0.8447\n",
      "Epoch: 084, Loss: 0.5190, Val: 0.8393, Test: 0.8440\n",
      "Epoch: 085, Loss: 0.5182, Val: 0.8391, Test: 0.8431\n",
      "Epoch: 086, Loss: 0.5206, Val: 0.8409, Test: 0.8417\n",
      "Epoch: 087, Loss: 0.5226, Val: 0.8412, Test: 0.8432\n",
      "Epoch: 088, Loss: 0.5231, Val: 0.8409, Test: 0.8451\n",
      "Epoch: 089, Loss: 0.5222, Val: 0.8409, Test: 0.8456\n",
      "Epoch: 090, Loss: 0.5214, Val: 0.8424, Test: 0.8450\n",
      "Epoch: 091, Loss: 0.5207, Val: 0.8412, Test: 0.8441\n",
      "Epoch: 092, Loss: 0.5197, Val: 0.8385, Test: 0.8429\n",
      "Epoch: 093, Loss: 0.5219, Val: 0.8369, Test: 0.8417\n",
      "Epoch: 094, Loss: 0.5205, Val: 0.8375, Test: 0.8417\n",
      "Epoch: 095, Loss: 0.5228, Val: 0.8409, Test: 0.8431\n",
      "Epoch: 096, Loss: 0.5131, Val: 0.8436, Test: 0.8459\n",
      "Epoch: 097, Loss: 0.5175, Val: 0.8434, Test: 0.8471\n",
      "Epoch: 098, Loss: 0.5179, Val: 0.8407, Test: 0.8447\n",
      "Epoch: 099, Loss: 0.5172, Val: 0.8381, Test: 0.8412\n",
      "Epoch: 100, Loss: 0.5165, Val: 0.8374, Test: 0.8400\n",
      "Final Test: 0.8459\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.nn import GCNConv\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from torch_geometric.utils import negative_sampling\n",
    "\n",
    "\n",
    "model = Net(9, 128, 64).to(device)\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    x_train = torch.concatenate((train_data.x, train_data.x_glase), axis=1)\n",
    "    z = model.encode(x_train, train_data.edge_index)\n",
    "\n",
    "    # We perform a new round of negative sampling for every training epoch:\n",
    "    neg_edge_index = negative_sampling(\n",
    "        edge_index=train_data.edge_index, num_nodes=train_data.num_nodes,\n",
    "        num_neg_samples=train_data.edge_label_index.size(1), method='sparse')\n",
    "\n",
    "    edge_label_index = torch.cat(\n",
    "        [train_data.edge_label_index, neg_edge_index],\n",
    "        dim=-1,\n",
    "    )\n",
    "    edge_label = torch.cat([\n",
    "        train_data.edge_label,\n",
    "        train_data.edge_label.new_zeros(neg_edge_index.size(1))\n",
    "    ], dim=0)\n",
    "\n",
    "    out = model.decode(z, edge_label_index).view(-1)\n",
    "    loss = criterion(out, edge_label)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(data):\n",
    "    model.eval()\n",
    "    x_test = torch.concatenate((data.x, data.x_glase), axis=1)\n",
    "    z = model.encode(x_test, data.edge_index)\n",
    "    out = model.decode(z, data.edge_label_index).view(-1).sigmoid()\n",
    "    return roc_auc_score(data.edge_label.cpu().numpy(), out.cpu().numpy())\n",
    "\n",
    "\n",
    "best_val_auc = final_test_auc = 0\n",
    "for epoch in range(1, 101):\n",
    "    loss = train()\n",
    "    val_auc = test(val_data)\n",
    "    test_auc = test(test_data)\n",
    "    if val_auc > best_val_auc:\n",
    "        best_val_auc = val_auc\n",
    "        final_test_auc = test_auc\n",
    "    print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Val: {val_auc:.4f}, '\n",
    "          f'Test: {test_auc:.4f}')\n",
    "\n",
    "print(f'Final Test: {final_test_auc:.4f}')\n",
    "\n",
    "x_test = torch.concatenate((test_data.x, test_data.x_glase), axis=1)\n",
    "z = model.encode(x_test, test_data.edge_index)\n",
    "final_edge_index = model.decode_all(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8571)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Predict on entire masked graph\n",
    "x_test = torch.concatenate((data.x, data.x_glase), axis=1)\n",
    "z = model.encode(x_test, data.edge_index)\n",
    "final_edge_index = model.decode_all(z)\n",
    "\n",
    "\n",
    "predicted_adj = to_dense_adj(final_edge_index).squeeze(0).to('cpu')\n",
    "(adj_matrix[senadores_no_presentes][:,n_P1+n_P2:]==predicted_adj[senadores_no_presentes][:,n_P1+n_P2:]).sum() / (n_P1_np+n_P2_np) / 230"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lase",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
