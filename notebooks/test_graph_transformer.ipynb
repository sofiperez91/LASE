{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[98, 12], edge_index=[2, 2416], x_init=[98, 4], x_ase=[98, 4], x_glase=[98, 4], x_grdpg=[98, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sofia/lase/lib/python3.10/site-packages/graspologic/embed/base.py:199: UserWarning: Input graph is not fully connected. Results may notbe optimal. You can compute the largest connected component byusing ``graspologic.utils.largest_connected_component``.\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import random\n",
    "import networkx as nx\n",
    "from torch_geometric.utils import to_dense_adj\n",
    "from graspologic.embed import AdjacencySpectralEmbed  \n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from models.onu_fuctions import load_un_dataset, create_un_graphs, process_un_graph, process_un_graph_2\n",
    "from models.link_prediction import train_link_prediction, eval_link_prediction, train_link_prediction_GAT, train_link_prediction_Transformer, train_link_prediction_GraphTransformer\n",
    "from models.glase_e2e_link_prediction import train_link_prediction_e2e, eval_link_prediction_e2e, train_link_prediction_GAT_e2e, train_link_prediction_Transformer_e2e, train_link_prediction_GraphTransformer_e2e\n",
    "# from models.link_prediction import Net2\n",
    "from models.RDPG_GD import GRDPG_GD_Armijo\n",
    "from models.GLASE_unshared_normalized import gLASE \n",
    "from training.generate_embeddings import generate_embeddings\n",
    "from torch_geometric.data import Data\n",
    "import torch_geometric.transforms as T\n",
    "\n",
    "\n",
    "import copy\n",
    "from typing import List\n",
    "votes_df = load_un_dataset('data/UNVotes-1.csv', unknown_votes=True)\n",
    "\n",
    "all_graphs = create_un_graphs(votes_df[votes_df.year==1946])\n",
    "\n",
    "unknown_countries = ['ISR', 'GRB', 'NDL', 'CUB', 'TUR', 'VNM']\n",
    "adj_matrix, country_indexes, res_indexes, unknown_edges, features, mask_nodes, mask, selected_resolutions, inverted_mask_matrix, mask_unknown = process_un_graph_2(all_graphs, mask_countries=unknown_countries, mask_threshold=0.1) \n",
    "\n",
    "# print(selected_resolutions)\n",
    "\n",
    "num_nodes = adj_matrix.shape[0]\n",
    "edge_index = torch.tensor(adj_matrix).nonzero().t().contiguous()\n",
    "\n",
    "# x_ase, x_grdpg, x_glase, masked_edge_index, edge_index_2, Q = generate_embeddings(adj_matrix, mask, d)\n",
    "# Q = Q.to('cuda')\n",
    "# edge_index_2 = edge_index_2.to('cuda')\n",
    "# mask = mask.to('cuda')\n",
    "\n",
    "\n",
    "## Calculate Embeddings\n",
    "d = 4\n",
    "## ASE \n",
    "adj_matrix = to_dense_adj(edge_index.to('cpu'), max_num_nodes=num_nodes).squeeze(0)\n",
    "ase = AdjacencySpectralEmbed(n_components=d, diag_aug=True, algorithm='full')\n",
    "masked_adj = adj_matrix*mask\n",
    "x_ase = ase.fit_transform(masked_adj.numpy())\n",
    "x_ase = torch.from_numpy(x_ase)\n",
    "\n",
    "masked_edge_index = masked_adj.nonzero().t().contiguous()\n",
    "\n",
    "# data = Data(x=features.float(), x_init=x_ase, x_ase=x_ase, x_glase=x_ase, x_grdpg=x_ase, edge_index=masked_edge_index)\n",
    "torch.manual_seed(42)\n",
    "random_features=torch.rand([num_nodes, 12])\n",
    "data = Data(x=random_features.float(), x_init=x_ase, x_ase=x_ase, x_glase=x_ase, x_grdpg=x_ase, edge_index=masked_edge_index)\n",
    "num_nodes = mask.shape[0]\n",
    "adj_matrix = to_dense_adj(edge_index.to('cpu'), max_num_nodes=num_nodes).squeeze(0)\n",
    "\n",
    "## Split Train, Val, Test\n",
    "device = 'cuda'\n",
    "transform = T.Compose([\n",
    "    T.ToDevice(device),\n",
    "    T.RandomLinkSplit(num_val=0.05, num_test=0.01, is_undirected=True,\n",
    "                    add_negative_train_samples=False),\n",
    "])\n",
    "\n",
    "train_data, val_data, test_data = transform(data)\n",
    "data = data.to('cuda')\n",
    "print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import dgl\n",
    "import dgl.function as fn\n",
    "import numpy as np\n",
    "\n",
    "\"\"\"\n",
    "    Graph Transformer Layer\n",
    "    \n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "    Util functions\n",
    "\"\"\"\n",
    "def src_dot_dst(src_field, dst_field, out_field):\n",
    "    def func(edges):\n",
    "        return {out_field: (edges.src[src_field] * edges.dst[dst_field]).sum(-1, keepdim=True)}\n",
    "    return func\n",
    "\n",
    "def scaled_exp(field, scale_constant):\n",
    "    def func(edges):\n",
    "        # clamp for softmax numerical stability\n",
    "        return {field: torch.exp((edges.data[field] / scale_constant).clamp(-5, 5))}\n",
    "\n",
    "    return func\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "    Single Attention Head\n",
    "\"\"\"\n",
    "\n",
    "class MultiHeadAttentionLayer(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim, num_heads, use_bias):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.out_dim = out_dim\n",
    "        self.num_heads = num_heads\n",
    "        \n",
    "        if use_bias:\n",
    "            self.Q = nn.Linear(in_dim, out_dim * num_heads, bias=True)\n",
    "            self.K = nn.Linear(in_dim, out_dim * num_heads, bias=True)\n",
    "            self.V = nn.Linear(in_dim, out_dim * num_heads, bias=True)\n",
    "        else:\n",
    "            self.Q = nn.Linear(in_dim, out_dim * num_heads, bias=False)\n",
    "            self.K = nn.Linear(in_dim, out_dim * num_heads, bias=False)\n",
    "            self.V = nn.Linear(in_dim, out_dim * num_heads, bias=False)\n",
    "        \n",
    "    \n",
    "    def propagate_attention(self, g):\n",
    "        # Compute attention score\n",
    "        g.apply_edges(src_dot_dst('K_h', 'Q_h', 'score')) #, edges)\n",
    "        g.apply_edges(scaled_exp('score', np.sqrt(self.out_dim)))\n",
    "\n",
    "        # Send weighted values to target nodes\n",
    "        eids = g.edges()\n",
    "        g.send_and_recv(eids, fn.src_mul_edge('V_h', 'score', 'V_h'), fn.sum('V_h', 'wV'))\n",
    "        g.send_and_recv(eids, fn.copy_edge('score', 'score'), fn.sum('score', 'z'))\n",
    "    \n",
    "    def forward(self, g, h):\n",
    "        \n",
    "        Q_h = self.Q(h)\n",
    "        K_h = self.K(h)\n",
    "        V_h = self.V(h)\n",
    "        \n",
    "        # Reshaping into [num_nodes, num_heads, feat_dim] to \n",
    "        # get projections for multi-head attention\n",
    "        g.ndata['Q_h'] = Q_h.view(-1, self.num_heads, self.out_dim)\n",
    "        g.ndata['K_h'] = K_h.view(-1, self.num_heads, self.out_dim)\n",
    "        g.ndata['V_h'] = V_h.view(-1, self.num_heads, self.out_dim)\n",
    "        \n",
    "        self.propagate_attention(g)\n",
    "        \n",
    "        head_out = g.ndata['wV']/g.ndata['z']\n",
    "        \n",
    "        return head_out\n",
    "    \n",
    "\n",
    "class GraphTransformerLayer(nn.Module):\n",
    "    \"\"\"\n",
    "        Param: \n",
    "    \"\"\"\n",
    "    def __init__(self, in_dim, out_dim, num_heads, dropout=0.0, layer_norm=False, batch_norm=True, residual=True, use_bias=False):\n",
    "        super().__init__()\n",
    "\n",
    "        self.in_channels = in_dim\n",
    "        self.out_channels = out_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.dropout = dropout\n",
    "        self.residual = residual\n",
    "        self.layer_norm = layer_norm        \n",
    "        self.batch_norm = batch_norm\n",
    "        \n",
    "        self.attention = MultiHeadAttentionLayer(in_dim, out_dim//num_heads, num_heads, use_bias)\n",
    "        \n",
    "        self.O = nn.Linear(out_dim, out_dim)\n",
    "\n",
    "        if self.layer_norm:\n",
    "            self.layer_norm1 = nn.LayerNorm(out_dim)\n",
    "            \n",
    "        if self.batch_norm:\n",
    "            self.batch_norm1 = nn.BatchNorm1d(out_dim)\n",
    "        \n",
    "        # FFN\n",
    "        self.FFN_layer1 = nn.Linear(out_dim, out_dim*2)\n",
    "        self.FFN_layer2 = nn.Linear(out_dim*2, out_dim)\n",
    "\n",
    "        if self.layer_norm:\n",
    "            self.layer_norm2 = nn.LayerNorm(out_dim)\n",
    "            \n",
    "        if self.batch_norm:\n",
    "            self.batch_norm2 = nn.BatchNorm1d(out_dim)\n",
    "        \n",
    "    def forward(self, g, h):\n",
    "        h_in1 = h # for first residual connection\n",
    "        \n",
    "        # multi-head attention out\n",
    "        attn_out = self.attention(g, h)\n",
    "        h = attn_out.view(-1, self.out_channels)\n",
    "        \n",
    "        h = F.dropout(h, self.dropout, training=self.training)\n",
    "        \n",
    "        h = self.O(h)\n",
    "        \n",
    "        if self.residual:\n",
    "            h = h_in1 + h # residual connection\n",
    "        \n",
    "        if self.layer_norm:\n",
    "            h = self.layer_norm1(h)\n",
    "            \n",
    "        if self.batch_norm:\n",
    "            h = self.batch_norm1(h)\n",
    "        \n",
    "        h_in2 = h # for second residual connection\n",
    "        \n",
    "        # FFN\n",
    "        h = self.FFN_layer1(h)\n",
    "        h = F.relu(h)\n",
    "        h = F.dropout(h, self.dropout, training=self.training)\n",
    "        h = self.FFN_layer2(h)\n",
    "\n",
    "        if self.residual:\n",
    "            h = h_in2 + h # residual connection\n",
    "        \n",
    "        if self.layer_norm:\n",
    "            h = self.layer_norm2(h)\n",
    "            \n",
    "        if self.batch_norm:\n",
    "            h = self.batch_norm2(h)       \n",
    "\n",
    "        return h\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return '{}(in_channels={}, out_channels={}, heads={}, residual={})'.format(self.__class__.__name__,\n",
    "                                             self.in_channels,\n",
    "                                             self.out_channels, self.num_heads, self.residual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "# from models.GraphTransformerLayer import GraphTransformerLayer\n",
    "from torch_geometric.utils import to_dgl\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "import torch \n",
    "from torch import nn\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.nn import TransformerConv\n",
    "from models.GraphTransformerLayer import GraphTransformerLayer\n",
    "from models.GAT import GATv2\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from torch_geometric.utils import negative_sampling\n",
    "from torch_geometric.utils import to_dense_adj\n",
    "from torch_geometric.utils import to_dgl\n",
    "import copy\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "class GraphTransformerLinkPrediction(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, pe_dim_in, pe_dim_out, n_layers, dropout, num_heads, batch_norm: int = True):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.feat_lin = nn.Linear(in_channels, out_channels, bias=True)\n",
    "        self.pe_lin = nn.Linear(pe_dim_in, pe_dim_out, bias=True)\n",
    "        self.layers = nn.ModuleList([GraphTransformerLayer(out_channels+pe_dim_out, out_channels+pe_dim_out, num_heads, dropout, batch_norm=batch_norm, layer_norm=True, residual=True) for _ in range(n_layers)])\n",
    "        \n",
    "\n",
    "    def encode(self, x_in, edge_index):\n",
    "        x_feat, x_pe = x_in\n",
    "        x_pe = self.pe_lin(x_pe)\n",
    "        x_feat=self.feat_lin(x_feat)\n",
    "        x = torch.concatenate((x_feat, x_pe), axis=1)\n",
    "        # print(x)\n",
    "        data = Data(x=x, edge_index=edge_index)\n",
    "        # Transform to DGL\n",
    "        g = to_dgl(data) \n",
    "        \n",
    "        # GraphTransformer Layers\n",
    "        for conv in self.layers:\n",
    "            x = conv(g, x)\n",
    "            # print(x)\n",
    "        return x\n",
    "    \n",
    "    def decode(self, z, edge_label_index):\n",
    "        return (z[edge_label_index[0]] * z[edge_label_index[1]]).sum(dim=-1)\n",
    "\n",
    "    def decode_all(self, z):\n",
    "        prob_adj = z @ z.t()\n",
    "        return (prob_adj > 0).nonzero(as_tuple=False).t()\n",
    "    \n",
    "def train(x_input, train_data, model, optimizer, criterion):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    z = model.encode(x_input, train_data.edge_index)\n",
    "\n",
    "    # We perform a new round of negative sampling for every training epoch:\n",
    "    neg_edge_index = negative_sampling(\n",
    "        edge_index=train_data.edge_index, num_nodes=train_data.num_nodes,\n",
    "        num_neg_samples=train_data.edge_label_index.size(1), method='sparse')\n",
    "\n",
    "    edge_label_index = torch.cat(\n",
    "        [train_data.edge_label_index, neg_edge_index],\n",
    "        dim=-1,\n",
    "    )\n",
    "    edge_label = torch.cat([\n",
    "        train_data.edge_label,\n",
    "        train_data.edge_label.new_zeros(neg_edge_index.size(1))\n",
    "    ], dim=0)\n",
    "\n",
    "    out = model.decode(z, edge_label_index).view(-1)\n",
    "    print(torch.sort(out))\n",
    "    print(edge_label[:5])\n",
    "    loss = criterion(out[:5], edge_label[:5])\n",
    "    print('Hola',loss)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.1016,  2.3111, -0.3753,  ..., -0.4465,  0.8163,  0.6778],\n",
       "        [-2.1781,  1.7504,  0.5823,  ...,  0.7038, -0.2071, -0.2766],\n",
       "        [-0.4197,  0.1038, -0.1684,  ..., -0.5292,  0.5420,  0.3487],\n",
       "        ...,\n",
       "        [-1.5097,  1.6042,  0.3253,  ...,  0.7505, -0.2385, -0.4173],\n",
       "        [-1.5945,  1.9640,  0.1765,  ...,  0.4531, -0.1168, -0.0580],\n",
       "        [-0.6371,  1.6956, -0.0449,  ...,  0.7677, -0.5222,  0.6367]],\n",
       "       device='cuda:0', grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = train_data.x, train_data.x_ase\n",
    "x_val = val_data.x, val_data.x_ase\n",
    "x_test = test_data.x, test_data.x_ase\n",
    "\n",
    "\n",
    "model = GraphTransformerLinkPrediction(12, 12, 4, 4, n_layers=1, dropout=0.5, num_heads=1, batch_norm=False).to(device)\n",
    "\n",
    "\n",
    "model\n",
    "\n",
    "# model_2 = train_link_prediction_GraphTransformer(x_train, x_val, x_test, train_data, val_data, test_data, input_dim=12, pe_dim=d, epochs = 101, \n",
    "#                                                     output_dim= 12, pe_out_dim= 4, n_layers= 1, dropout=0.5, num_heads=1)\n",
    "\n",
    "\n",
    "model.encode(x_train, train_data.edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "empty(): argument 'size' must be tuple of ints, but found element of type Tensor at pos 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[63], line 23\u001b[0m\n\u001b[1;32m     19\u001b[0m             final_test_auc \u001b[38;5;241m=\u001b[39m test_auc\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n\u001b[0;32m---> 23\u001b[0m \u001b[43mtrain_link_prediction_GraphTransformer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m12\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpe_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43md\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m101\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m                                                     \u001b[49m\u001b[43moutput_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m12\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpe_out_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_layers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdropout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_heads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_norm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.000000000001\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[63], line 7\u001b[0m, in \u001b[0;36mtrain_link_prediction_GraphTransformer\u001b[0;34m(x_train, x_val, x_test, train_data, val_data, test_data, input_dim, pe_dim, epochs, output_dim, pe_out_dim, n_layers, dropout, num_heads, batch_norm, lr)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_link_prediction_GraphTransformer\u001b[39m(x_train, x_val, x_test, train_data, val_data, test_data, input_dim, pe_dim, epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m301\u001b[39m, \n\u001b[1;32m      4\u001b[0m                                            output_dim: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m32\u001b[39m, pe_out_dim: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m8\u001b[39m, n_layers: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m, dropout:\u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m, \n\u001b[1;32m      5\u001b[0m                                            num_heads: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, batch_norm: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, lr: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.01\u001b[39m): \n\u001b[1;32m      6\u001b[0m     device \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 7\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mGraphTransformerLinkPrediction\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpe_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpe_out_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_layers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_layers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdropout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_heads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_heads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_norm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28mprint\u001b[39m(model)\n\u001b[1;32m      9\u001b[0m     optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(params\u001b[38;5;241m=\u001b[39mmodel\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mlr)\n",
      "Cell \u001b[0;32mIn[61], line 24\u001b[0m, in \u001b[0;36mGraphTransformerLinkPrediction.__init__\u001b[0;34m(self, in_channels, out_channels, pe_dim_in, pe_dim_out, n_layers, dropout, num_heads, batch_norm)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeat_lin \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mLinear(in_channels, out_channels, bias\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 24\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpe_lin \u001b[38;5;241m=\u001b[39m \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLinear\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpe_dim_in\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpe_dim_out\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mModuleList([GraphTransformerLayer(out_channels\u001b[38;5;241m+\u001b[39mpe_dim_out, out_channels\u001b[38;5;241m+\u001b[39mpe_dim_out, num_heads, dropout, batch_norm\u001b[38;5;241m=\u001b[39mbatch_norm, layer_norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, residual\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_layers)])\n",
      "File \u001b[0;32m~/lase/lib/python3.10/site-packages/torch/nn/modules/linear.py:96\u001b[0m, in \u001b[0;36mLinear.__init__\u001b[0;34m(self, in_features, out_features, bias, device, dtype)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_features \u001b[38;5;241m=\u001b[39m in_features\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout_features \u001b[38;5;241m=\u001b[39m out_features\n\u001b[0;32m---> 96\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight \u001b[38;5;241m=\u001b[39m Parameter(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mempty\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_features\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfactory_kwargs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m bias:\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias \u001b[38;5;241m=\u001b[39m Parameter(torch\u001b[38;5;241m.\u001b[39mempty(out_features, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfactory_kwargs))\n",
      "\u001b[0;31mTypeError\u001b[0m: empty(): argument 'size' must be tuple of ints, but found element of type Tensor at pos 2"
     ]
    }
   ],
   "source": [
    "from models.link_prediction import test\n",
    "\n",
    "def train_link_prediction_GraphTransformer(x_train, x_val, x_test, train_data, val_data, test_data, input_dim, pe_dim, epochs = 301, \n",
    "                                           output_dim: int = 32, pe_out_dim: int = 8, n_layers: int = 3, dropout:int =0.5, \n",
    "                                           num_heads: int =4, batch_norm: bool = True, lr: int = 0.01): \n",
    "    device = \"cuda\"\n",
    "    model = GraphTransformerLinkPrediction(input_dim, output_dim, pe_dim, pe_out_dim, n_layers=n_layers, dropout=dropout, num_heads=num_heads, batch_norm=batch_norm).to(device)\n",
    "    print(model)\n",
    "    optimizer = torch.optim.Adam(params=model.parameters(), lr=lr)\n",
    "    criterion = torch.nn.BCEWithLogitsLoss()\n",
    "    best_val_auc = final_test_auc = 0\n",
    "    for epoch in range(1, epochs):\n",
    "        loss = train(x_train, train_data, model, optimizer, criterion)\n",
    "        print(loss)\n",
    "        val_auc = test(x_val, val_data, model)\n",
    "        test_auc = test(x_test, test_data, model)\n",
    "        if val_auc > best_val_auc:\n",
    "            best_val_auc = val_auc\n",
    "            final_test_auc = test_auc\n",
    "    return model\n",
    "\n",
    "\n",
    "train_link_prediction_GraphTransformer(x_train, x_val, x_test, train_data, val_data, test_data, input_dim=12, pe_dim=d, epochs = 101, \n",
    "                                                     output_dim= 12, pe_out_dim= 4, n_layers= 1, dropout=0.5, num_heads=1, batch_norm=False, lr=0.000000000001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2276, 16])\n",
      "torch.Size([2276, 16])\n",
      "torch.Size([2276, 16])\n",
      "torch.Size([2276])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.return_types.sort(\n",
       "values=tensor([2.2996, 3.2255, 3.2734,  ...,    nan,    nan,    nan], device='cuda:0',\n",
       "       grad_fn=<SortBackward0>),\n",
       "indices=tensor([ 578,  879,  654,  ..., 2071, 2174, 2274], device='cuda:0'))"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "z = model.encode(x_train, train_data.edge_index)\n",
    "\n",
    "\n",
    "# We perform a new round of negative sampling for every training epoch:\n",
    "neg_edge_index = negative_sampling(\n",
    "    edge_index=train_data.edge_index, num_nodes=train_data.num_nodes,\n",
    "    num_neg_samples=train_data.edge_label_index.size(1), method='sparse')\n",
    "\n",
    "edge_label_index = torch.cat(\n",
    "    [train_data.edge_label_index, neg_edge_index],\n",
    "    dim=-1,\n",
    ")\n",
    "edge_label = torch.cat([\n",
    "    train_data.edge_label,\n",
    "    train_data.edge_label.new_zeros(neg_edge_index.size(1))\n",
    "], dim=0)\n",
    "\n",
    "\n",
    "a = z[edge_label_index[0]]\n",
    "b = z[edge_label_index[1]]\n",
    "\n",
    "# print(torch.sort(z[edge_label_index[0]]))\n",
    "# print(z[edge_label_index[1]])\n",
    "\n",
    "print(a.shape)\n",
    "print(b.shape)\n",
    "c = a*b\n",
    "print(c.shape)\n",
    "\n",
    "d = (a*b).sum(dim=-1)\n",
    "print(d.shape)\n",
    "torch.sort((a*b).sum(dim=-1))\n",
    "# edge_label_index\n",
    "\n",
    "# torch.sort(out),;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boolean Mask: tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]], device='cuda:0')\n",
      "Indices of NaN Values: tensor([[72,  0],\n",
      "        [72,  1],\n",
      "        [72,  2],\n",
      "        [72,  3],\n",
      "        [72,  4],\n",
      "        [72,  5],\n",
      "        [72,  6],\n",
      "        [72,  7],\n",
      "        [72,  8],\n",
      "        [72,  9],\n",
      "        [72, 10],\n",
      "        [72, 11],\n",
      "        [72, 12],\n",
      "        [72, 13],\n",
      "        [72, 14],\n",
      "        [72, 15]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Example tensor with NaN values\n",
    "\n",
    "# Create a boolean mask tensor indicating where the entries are NaN\n",
    "\n",
    "z = model.encode(x_train, train_data.edge_index)\n",
    "nan_mask = torch.isnan(z)\n",
    "\n",
    "print(\"Boolean Mask:\", nan_mask)\n",
    "\n",
    "# Get the indices where NaN values occur\n",
    "nan_indices = torch.nonzero(nan_mask).squeeze()\n",
    "\n",
    "print(\"Indices of NaN Values:\", nan_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6272)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = torch.tensor([0.1421, 0.1502, 0.1686, 0.1014, 0.1211])\n",
    "label = torch.tensor([1., 1., 1., 1., 1.])\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "criterion(out, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lase",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
